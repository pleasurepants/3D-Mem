=== JOB START ===
Sun Jun 22 10:47:40 PM CEST 2025
worker-9
Sun Jun 22 22:47:40 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA L40S                    Off | 00000000:01:00.0 Off |                    0 |
| N/A   49C    P0             117W / 350W |  17430MiB / 46068MiB |     66%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA L40S                    Off | 00000000:02:00.0 Off |                    0 |
| N/A   32C    P8              32W / 350W |      0MiB / 46068MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA L40S                    Off | 00000000:C1:00.0 Off |                    0 |
| N/A   31C    P8              30W / 350W |      0MiB / 46068MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA L40S                    Off | 00000000:C2:00.0 Off |                    0 |
| N/A   33C    P8              34W / 350W |      0MiB / 46068MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   2726126      C   python                                    17424MiB |
+---------------------------------------------------------------------------------------+
SLURM_JOB_ID: 75213
[INFO] CUDA_VISIBLE_DEVICES=1,2
[INFO] Starting vLLM (minicpm) server on GPU 0...
[INFO] Waiting for vLLM (minicpm) server to be ready...
  ... waiting (2s)
  ... waiting (4s)
  ... waiting (6s)
  ... waiting (8s)
  ... waiting (10s)
  ... waiting (12s)
  ... waiting (14s)
  ... waiting (16s)
INFO 06-22 22:47:57 [__init__.py:244] Automatically detected platform cuda.
  ... waiting (18s)
  ... waiting (20s)
  ... waiting (22s)
  ... waiting (24s)
  ... waiting (26s)
  ... waiting (28s)
  ... waiting (30s)
  ... waiting (32s)
  ... waiting (34s)
INFO 06-22 22:48:15 [api_server.py:1287] vLLM API server version 0.9.1
INFO 06-22 22:48:17 [cli_args.py:309] non-default args: {'model': 'openbmb/MiniCPM-V-2_6', 'trust_remote_code': True, 'served_model_name': ['minicpm'], 'limit_mm_per_prompt': {'image': 20}}
  ... waiting (36s)
  ... waiting (38s)
  ... waiting (40s)
  ... waiting (42s)
  ... waiting (44s)
  ... waiting (46s)
  ... waiting (48s)
  ... waiting (50s)
  ... waiting (52s)
  ... waiting (54s)
  ... waiting (56s)
  ... waiting (58s)
  ... waiting (60s)
INFO 06-22 22:48:42 [config.py:823] This model supports multiple tasks: {'embed', 'classify', 'reward', 'score', 'generate'}. Defaulting to 'generate'.
INFO 06-22 22:48:42 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=2048.
  ... waiting (62s)
  ... waiting (64s)
  ... waiting (66s)
  ... waiting (68s)
WARNING 06-22 22:48:55 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
  ... waiting (70s)
  ... waiting (72s)
  ... waiting (74s)
  ... waiting (76s)
INFO 06-22 22:49:03 [__init__.py:244] Automatically detected platform cuda.
  ... waiting (78s)
  ... waiting (80s)
  ... waiting (82s)
  ... waiting (84s)
  ... waiting (86s)
INFO 06-22 22:49:13 [core.py:455] Waiting for init message from front-end.
INFO 06-22 22:49:13 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='openbmb/MiniCPM-V-2_6', speculative_config=None, tokenizer='openbmb/MiniCPM-V-2_6', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=minicpm, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
  ... waiting (88s)
WARNING 06-22 22:49:13 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x71a902898430>
ERROR 06-22 22:49:14 [core.py:515] EngineCore failed to start.
ERROR 06-22 22:49:14 [core.py:515] Traceback (most recent call last):
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 506, in run_engine_core
ERROR 06-22 22:49:14 [core.py:515]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 390, in __init__
ERROR 06-22 22:49:14 [core.py:515]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 76, in __init__
ERROR 06-22 22:49:14 [core.py:515]     self.model_executor = executor_class(vllm_config)
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
ERROR 06-22 22:49:14 [core.py:515]     self._init_executor()
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 06-22 22:49:14 [core.py:515]     self.collective_rpc("init_device")
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
ERROR 06-22 22:49:14 [core.py:515]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/utils.py", line 2671, in run_method
ERROR 06-22 22:49:14 [core.py:515]     return func(*args, **kwargs)
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 606, in init_device
ERROR 06-22 22:49:14 [core.py:515]     self.worker.init_device()  # type: ignore
ERROR 06-22 22:49:14 [core.py:515]   File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 140, in init_device
ERROR 06-22 22:49:14 [core.py:515]     raise ValueError(
ERROR 06-22 22:49:14 [core.py:515] ValueError: Free memory on device (27.06/44.53 GiB) on startup is less than desired GPU memory utilization (0.9, 40.07 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
Process EngineCore_0:
Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 519, in run_engine_core
    raise e
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 506, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 390, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 76, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
    self._init_executor()
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
    self.collective_rpc("init_device")
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/utils.py", line 2671, in run_method
    return func(*args, **kwargs)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 606, in init_device
    self.worker.init_device()  # type: ignore
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 140, in init_device
    raise ValueError(
ValueError: Free memory on device (27.06/44.53 GiB) on startup is less than desired GPU memory utilization (0.9, 40.07 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
  ... waiting (90s)
Traceback (most recent call last):
  File "/home/wiss/zhang/anaconda3/envs/vllm/bin/vllm", line 8, in <module>
    sys.exit(main())
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/cli/main.py", line 59, in main
    args.dispatch_function(args)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/cli/serve.py", line 58, in cmd
    uvloop.run(run_server(args))
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/uvloop/__init__.py", line 82, in run
    return loop.run_until_complete(wrapper())
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/uvloop/__init__.py", line 61, in wrapper
    return await main
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1323, in run_server
    await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1343, in run_server_worker
    async with build_async_engine_client(args, client_config) as engine_client:
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/contextlib.py", line 199, in __aenter__
    return await anext(self.gen)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 155, in build_async_engine_client
    async with build_async_engine_client_from_engine_args(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/contextlib.py", line 199, in __aenter__
    return await anext(self.gen)
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 191, in build_async_engine_client_from_engine_args
    async_llm = AsyncLLM.from_vllm_config(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 162, in from_vllm_config
    return cls(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 124, in __init__
    self.engine_core = EngineCoreClient.make_async_mp_client(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 93, in make_async_mp_client
    return AsyncMPClient(vllm_config, executor_class, log_stats,
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 716, in __init__
    super().__init__(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 422, in __init__
    self._init_engines_direct(vllm_config, local_only,
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 491, in _init_engines_direct
    self._wait_for_engine_startup(handshake_socket, input_address,
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 511, in _wait_for_engine_startup
    wait_for_engine_startup(
  File "/home/wiss/zhang/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/v1/utils.py", line 494, in wait_for_engine_startup
    raise RuntimeError("Engine core initialization failed. "
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
  ... waiting (92s)
  ... waiting (94s)
  ... waiting (96s)
  ... waiting (98s)
  ... waiting (100s)
  ... waiting (102s)
  ... waiting (104s)
  ... waiting (106s)
  ... waiting (108s)
  ... waiting (110s)
  ... waiting (112s)
  ... waiting (114s)
  ... waiting (116s)
  ... waiting (118s)
  ... waiting (120s)
  ... waiting (122s)
  ... waiting (124s)
  ... waiting (126s)
  ... waiting (128s)
  ... waiting (130s)
  ... waiting (132s)
  ... waiting (134s)
  ... waiting (136s)
  ... waiting (138s)
  ... waiting (140s)
  ... waiting (142s)
  ... waiting (144s)
  ... waiting (146s)
  ... waiting (148s)
  ... waiting (150s)
  ... waiting (152s)
  ... waiting (154s)
  ... waiting (156s)
  ... waiting (158s)
slurmstepd: error: *** JOB 75213 ON worker-9 CANCELLED AT 2025-06-22T22:50:26 ***
