Fri May 30 07:15:41 PM CEST 2025
worker-2
/home/wiss/zhang/anaconda3/envs/3dmem/bin/python
Running on MASTER_NODE=worker-2, MASTER_PORT=8924, RDZV_ID=7527
2.3.0
00:00:00 - Downloading `prism-dinosiglip+7b from HF Hub
00:00:00 - Found Config =>> Loading & Freezing [bold blue]prism-dinosiglip+7b[/] with:
             Vision Backbone =>> [bold]dinosiglip-vit-so-384px[/]
             LLM Backbone    =>> [bold]llama2-7b-pure[/]
             Arch Specifier  =>> [bold]no-align+fused-gelu-mlp[/]
             Checkpoint Path =>> [underline]`/home/wiss/zhang/.cache/huggingface/hub/models--TRI-ML--prismatic-vlms/snapshots/a3ba8a19c453a82eaf5a3fb1e699dd9e441f0a12/prism-dinosiglip+7b/checkpoints/latest-checkpoint.pt`[/]
00:00:00 - Loading Vision Backbone [bold]dinosiglip-vit-so-384px[/]
00:00:04 - Loading pretrained weights from Hugging Face hub (timm/vit_large_patch14_reg4_dinov2.lvd142m)
00:00:04 - [timm/vit_large_patch14_reg4_dinov2.lvd142m] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
00:00:04 - Resized position embedding: (37, 37) to (27, 27).
00:00:10 - Loading pretrained weights from Hugging Face hub (('timm/ViT-SO400M-14-SigLIP-384', 'open_clip_pytorch_model.bin'))
00:00:10 - [timm/ViT-SO400M-14-SigLIP-384] Safe alternative available for 'open_clip_pytorch_model.bin' (as 'open_clip_model.safetensors'). Loading weights using safetensors.
00:00:10 - Loading Pretrained LLM [bold]llama2-7b-pure[/] via HF Transformers
00:00:10 - Building empty [bold]llama2[/] LLM from [underline]`meta-llama/Llama-2-7b-hf`[/]
00:01:31 - Loading [bold]llama2[/] (Fast) Tokenizer via the AutoTokenizer API
00:01:35 - Loading VLM [bold blue]prism-dinosiglip+7b[/] from Checkpoint; Freezing Weights ðŸ¥¶
00:01:54 - Loaded VLM in 114.685s
00:01:54 - ***** Running exp_eval_aeqa *****
00:01:54 - Total number of questions: 41
00:01:54 - number of questions after splitting: 41
00:01:54 - question path: data/aeqa_questions-41.json
00:01:54 - Load YOLO model yolov8x-world.pt successful!
00:01:57 - Load SAM model sam_l.pt successful!
00:01:57 - Loaded ViT-B-32 model config.
00:01:59 - Loading pretrained ViT-B-32 weights (laion2b_s34b_b79k).
00:01:59 - Load CLIP model successful!
00:01:59 - 
========
Index: 0 Scene: 00824-Dd4bFSTQ8gi
00:02:03 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:02:03 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:02:08 - 

Question id 00c2be2a-1377-4fae-a889-30936b7890c3 initialization successful!
00:02:08 - 
== step: 0
00:02:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:02:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:02:14 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:02:15 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:02:17 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:02:18 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:02:20 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:02:21 - Step 0, update snapshots, 12 objects, 4 snapshots
00:02:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:02:23 - Prefiltering selected classes: ['table']
00:02:23 - Prefiltering snapshot: 4 -> 1
UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )
00:02:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:02:26 - Response: [snapshot 0]
Reason: [There is no oven visible.]
00:02:26 - Prediction: snapshot, 0
00:02:26 - The index of target snapshot 0
00:02:26 - Pred_target_class: bed plate plate table chair folded chair
00:02:26 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:02:26 - Current position: [     7.0147    0.068824      1.6036], 0.141
00:02:29 - Question id 00c2be2a-1377-4fae-a889-30936b7890c3 finished after arriving at target!
00:02:29 - Question id 00c2be2a-1377-4fae-a889-30936b7890c3 finish successfully, 0.14142135623730953 length
00:02:29 - 1/41: Success rate: 1/1
00:02:29 - Mean path length for success exploration: 0.14142135623730953
00:02:29 - Filtered snapshots/Total snapshots/Total frames: 1/4/5
00:02:29 - Scene graph of question 00c2be2a-1377-4fae-a889-30936b7890c3:
00:02:29 - Question: What is hanging from the oven handle?
00:02:29 - Answer: A towel
00:02:29 - Prediction: There is no oven visible.
00:02:29 - 0-view_0.png:
00:02:29 - 	1: potted plant 2
00:02:29 - 	2: picture 2
00:02:29 - 	4: folded chair 1
00:02:29 - 0-view_5.png:
00:02:29 - 	3: bed 3
00:02:29 - 	7: plate 3
00:02:29 - 	9: folded chair 2
00:02:29 - 	11: plate 2
00:02:29 - 	12: table 2
00:02:29 - 	21: chair 1
00:02:29 - 0-view_3.png:
00:02:29 - 	8: sofa chair 1
00:02:29 - 	10: pillow 1
00:02:29 - 0-view_4.png:
00:02:29 - 	14: picture 1
00:02:29 - 
========
Index: 1 Scene: 00876-mv2HUxq3B53
00:02:35 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:02:35 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:02:35 - 

Question id 013bb857-f47d-4b50-add4-023cc4ff414c initialization successful!
00:02:35 - 
== step: 0
00:02:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:02:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:02:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:02:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:02:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:02:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:02:45 - Step 0, update snapshots, 15 objects, 4 snapshots
00:02:48 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:02:48 - Prefiltering selected classes: ['cabinet']
00:02:48 - Prefiltering snapshot: 4 -> 1
00:02:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:02:50 - Response: [snapshot 0]
Reason: [I can't determine the material of the stools in the kitchen from this image.]
00:02:50 - Prediction: snapshot, 0
00:02:50 - The index of target snapshot 0
00:02:50 - Pred_target_class: cabinet picture curtain picture tv
00:02:50 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:02:50 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:02:52 - 
== step: 1
00:02:53 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:02:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:02:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:02:57 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:02:57 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:03:00 - Question id 013bb857-f47d-4b50-add4-023cc4ff414c finished after arriving at target!
00:03:00 - Question id 013bb857-f47d-4b50-add4-023cc4ff414c finish successfully, 1.5295630140987002 length
00:03:00 - 2/41: Success rate: 2/2
00:03:00 - Mean path length for success exploration: 0.8354921851680048
00:03:00 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:03:00 - Scene graph of question 013bb857-f47d-4b50-add4-023cc4ff414c:
00:03:00 - Question: What material are the stools in the kitchen made out of?
00:03:00 - Answer: Leather
00:03:00 - Prediction: I can't determine the material of the stools in the kitchen from this image.
00:03:00 - 0-view_1.png:
00:03:00 - 	1: telephone 1
00:03:00 - 	4: pillow 1
00:03:00 - 0-view_6.png:
00:03:00 - 	2: nightstand 4
00:03:00 - 	3: lamp 3
00:03:00 - 	27: picture 1
00:03:00 - 0-view_3.png:
00:03:00 - 	7: bed 6
00:03:00 - 	8: pillow 3
00:03:00 - 	12: pillow 1
00:03:00 - 	13: pillow 1
00:03:00 - 	14: blanket 1
00:03:00 - 0-view_5.png:
00:03:00 - 	11: cabinet 5
00:03:00 - 	16: picture 3
00:03:00 - 	18: curtain 3
00:03:00 - 	21: picture 1
00:03:00 - 	23: tv 1
00:03:00 - 
========
Index: 2 Scene: 00848-ziup5kvtCCR
00:03:03 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:03:03 - Load scene 00848-ziup5kvtCCR successfully with semantic texture
00:03:03 - 

Question id 01fcc568-f51e-4e12-b976-5dc8d554135a initialization successful!
00:03:03 - 
== step: 0
00:03:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.15 seconds
00:03:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:03:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:03:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:03:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:03:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:03:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:03:14 - Step 0, update snapshots, 25 objects, 7 snapshots
00:03:17 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:03:17 - Prefiltering selected classes: ['sofa chair', 'couch', 'pillow', 'cabinet']
00:03:17 - Prefiltering snapshot: 7 -> 4
00:03:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:03:20 - Response: [snapshot 0]
Reason: [There is no teddy bear present.]
00:03:20 - Prediction: snapshot, 0
00:03:20 - The index of target snapshot 0
00:03:20 - Pred_target_class: lamp coffee table potted plant pillow pillow pillow pillow couch
00:03:20 - Next choice Snapshot of 0-view_0.png
00:03:20 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 1 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:03:20 - Current position: [    0.21692    0.021223      7.1057], 0.000
00:03:22 - Question id 01fcc568-f51e-4e12-b976-5dc8d554135a finished after arriving at target!
00:03:22 - Question id 01fcc568-f51e-4e12-b976-5dc8d554135a finish successfully, 0.0 length
00:03:22 - 3/41: Success rate: 3/3
00:03:22 - Mean path length for success exploration: 0.5569947901120033
00:03:22 - Filtered snapshots/Total snapshots/Total frames: 4/7/7
00:03:22 - Scene graph of question 01fcc568-f51e-4e12-b976-5dc8d554135a:
00:03:22 - Question: Where is the teddy bear?
00:03:22 - Answer: In the dog bed in the living room.
00:03:22 - Prediction: There is no teddy bear present.
00:03:22 - 0-view_0.png:
00:03:22 - 	1: lamp 1
00:03:22 - 	2: pillow 3
00:03:22 - 	4: couch 2
00:03:22 - 	5: coffee table 1
00:03:22 - 	6: potted plant 1
00:03:22 - 	7: pillow 2
00:03:22 - 	8: pillow 2
00:03:22 - 	9: pillow 1
00:03:22 - 0-view_2.png:
00:03:22 - 	3: pillow 3
00:03:22 - 	18: couch 2
00:03:22 - 0-view_1.png:
00:03:22 - 	10: coffee table 3
00:03:22 - 	11: sofa chair 3
00:03:22 - 	14: pillow 1
00:03:22 - 0-view_6.png:
00:03:22 - 	21: cabinet 3
00:03:22 - 	25: tv 2
00:03:22 - 	26: potted plant 3
00:03:22 - 0-view_3.png:
00:03:22 - 	24: mirror 1
00:03:22 - 0-view_4.png:
00:03:22 - 	28: clock 2
00:03:22 - 	29: bottle 2
00:03:22 - 0-view_5.png:
00:03:22 - 	30: mirror 2
00:03:22 - 	32: clock 2
00:03:22 - 	35: lamp 2
00:03:22 - 	39: curtain 1
00:03:22 - 	40: candle 1
00:03:22 - 	41: potted plant 1
00:03:23 - 
========
Index: 3 Scene: 00848-ziup5kvtCCR
00:03:26 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:03:26 - Load scene 00848-ziup5kvtCCR successfully with semantic texture
00:03:26 - 

Question id 0df60236-15ad-4166-a31a-a98d14214fdb initialization successful!
00:03:26 - 
== step: 0
00:03:27 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.15 seconds
00:03:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:03:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:03:32 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:03:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:03:35 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:03:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:03:37 - Step 0, update snapshots, 25 objects, 7 snapshots
00:03:40 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:03:40 - Prefiltering selected classes: ['clock']
00:03:40 - Prefiltering snapshot: 7 -> 2
00:03:42 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:03:42 - Response: [snapshot 1]
Reason: [The numbers on the clock are Roman numerals.]
00:03:42 - Prediction: snapshot, 1
00:03:42 - The index of target snapshot 2
00:03:42 - Pred_target_class: clock bottle
00:03:42 - Next choice Snapshot of 0-view_4.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:03:42 - Current position: [   -0.38308    0.021223      6.8057], 0.671
00:03:45 - Question id 0df60236-15ad-4166-a31a-a98d14214fdb finished after arriving at target!
00:03:45 - Question id 0df60236-15ad-4166-a31a-a98d14214fdb finish successfully, 0.670820393249937 length
00:03:45 - 4/41: Success rate: 4/4
00:03:45 - Mean path length for success exploration: 0.5854511908964867
00:03:45 - Filtered snapshots/Total snapshots/Total frames: 2/7/7
00:03:45 - Scene graph of question 0df60236-15ad-4166-a31a-a98d14214fdb:
00:03:45 - Question: What type of numbers are on the clock?
00:03:45 - Answer: Roman numerals
00:03:45 - Prediction: The numbers on the clock are Roman numerals.
00:03:45 - 0-view_0.png:
00:03:45 - 	1: lamp 1
00:03:45 - 	2: pillow 3
00:03:45 - 	4: couch 2
00:03:45 - 	5: coffee table 1
00:03:45 - 	6: potted plant 1
00:03:45 - 	7: pillow 2
00:03:45 - 	8: pillow 2
00:03:45 - 	9: pillow 1
00:03:45 - 0-view_2.png:
00:03:45 - 	3: pillow 3
00:03:45 - 	18: couch 2
00:03:45 - 0-view_1.png:
00:03:45 - 	10: coffee table 3
00:03:45 - 	11: sofa chair 3
00:03:45 - 	14: pillow 1
00:03:45 - 0-view_6.png:
00:03:45 - 	21: cabinet 3
00:03:45 - 	25: tv 2
00:03:45 - 	26: potted plant 3
00:03:45 - 0-view_3.png:
00:03:45 - 	24: mirror 1
00:03:45 - 0-view_4.png:
00:03:45 - 	28: clock 2
00:03:45 - 	29: bottle 2
00:03:45 - 0-view_5.png:
00:03:45 - 	30: mirror 2
00:03:45 - 	32: clock 2
00:03:45 - 	35: lamp 2
00:03:45 - 	39: curtain 1
00:03:45 - 	40: candle 1
00:03:45 - 	41: potted plant 1
00:03:45 - 
========
Index: 4 Scene: 00880-Nfvxx8J5NCo
00:03:48 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:03:48 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:03:48 - 

Question id 109eaad4-6e68-4da1-8f98-a0d8589ec26d initialization successful!
00:03:48 - 
== step: 0
00:03:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:03:50 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:03:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:03:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:03:55 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:03:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:03:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:04:00 - Step 0, update snapshots, 24 objects, 6 snapshots
00:04:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:04:03 - Prefiltering selected classes: ['shelf', 'cabinet', 'counter', 'coffee table', 'refrigerator']
00:04:03 - Prefiltering snapshot: 6 -> 5
00:04:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:04:07 - Response: [snapshot 3]
Reason: [You can keep a photo frame on the shelf.]
00:04:07 - Prediction: snapshot, 3
00:04:07 - The index of target snapshot 3
00:04:07 - Pred_target_class: shelf picture
00:04:07 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:04:07 - Current position: [    -8.8166     0.18086     -1.0476], 0.990
00:04:09 - 
== step: 1
00:04:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:04:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:04:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:04:14 - Step 1, update snapshots, 28 objects, 7 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:04:15 - Current position: [    -8.3166     0.18086     -1.8476], 1.933
00:04:19 - 
== step: 2
00:04:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:04:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:04:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:04:23 - Step 2, update snapshots, 29 objects, 9 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:04:24 - Current position: [    -8.0166     0.18086     -2.0476], 2.294
00:04:27 - Question id 109eaad4-6e68-4da1-8f98-a0d8589ec26d finished after arriving at target!
00:04:27 - Question id 109eaad4-6e68-4da1-8f98-a0d8589ec26d finish successfully, 2.293902734413226 length
00:04:27 - 5/41: Success rate: 5/5
00:04:27 - Mean path length for success exploration: 0.9271414995998345
00:04:27 - Filtered snapshots/Total snapshots/Total frames: 5/9/13
00:04:27 - Scene graph of question 109eaad4-6e68-4da1-8f98-a0d8589ec26d:
00:04:27 - Question: where can I keep a photo frame?
00:04:27 - Answer: on the counter below the television with other frames
00:04:27 - Prediction: You can keep a photo frame on the shelf.
00:04:27 - 0-view_0.png:
00:04:27 - 	1: couch 9
00:04:27 - 	2: coffee table 4
00:04:27 - 	3: book 4
00:04:27 - 	4: mat 1
00:04:27 - 0-view_6.png:
00:04:27 - 	8: fan 2
00:04:27 - 0-view_2.png:
00:04:27 - 	10: microwave 1
00:04:27 - 	11: stool 1
00:04:27 - 	12: trash bin 1
00:04:27 - 	13: counter 1
00:04:27 - 0-view_4.png:
00:04:27 - 	14: sink 4
00:04:27 - 	15: refrigerator 4
00:04:27 - 	25: paper bag 6
00:04:27 - 	27: tissue box 2
00:04:27 - 	32: cabinet 1
00:04:27 - 0-view_3.png:
00:04:27 - 	16: stool 3
00:04:27 - 	17: stool 2
00:04:27 - 	18: stool 2
00:04:27 - 	19: microwave 2
00:04:27 - 	20: picture 3
00:04:27 - 	21: shelf 2
00:04:27 - 	23: stove 2
00:04:27 - 1-view_0.png:
00:04:27 - 	29: picture 4
00:04:27 - 	46: picture 3
00:04:27 - 1-view_2.png:
00:04:27 - 	37: shelf 6
00:04:27 - 	38: picture 2
00:04:27 - 	55: picture 4
00:04:27 - 1-view_1.png:
00:04:27 - 	52: fan 1
00:04:27 - 	56: picture 3
00:04:27 - 2-view_0.png:
00:04:27 - 	71: book 1
00:04:27 - 
========
Index: 5 Scene: 00876-mv2HUxq3B53
00:04:33 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:04:33 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:04:33 - 

Question id 1b36e675-74ff-46ad-8caa-c33da46a5a67 initialization successful!
00:04:33 - 
== step: 0
00:04:35 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:04:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:04:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:04:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:04:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:04:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:04:43 - Step 0, update snapshots, 15 objects, 4 snapshots
00:04:45 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:04:45 - Prefiltering selected classes: ['cabinet']
00:04:45 - Prefiltering snapshot: 4 -> 1
00:04:48 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:04:48 - Response: [snapshot 0]
Reason: [Consider setting the table near the window to enjoy the natural light and possibly a view, creating a pleasant atmosphere for a summer evening dinner party.]
00:04:48 - Prediction: snapshot, 0
00:04:48 - The index of target snapshot 0
00:04:48 - Pred_target_class: cabinet picture curtain picture tv
00:04:48 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:04:48 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:04:50 - 
== step: 1
00:04:51 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:04:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:04:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:04:55 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:04:55 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:04:58 - Question id 1b36e675-74ff-46ad-8caa-c33da46a5a67 finished after arriving at target!
00:04:58 - Question id 1b36e675-74ff-46ad-8caa-c33da46a5a67 finish successfully, 1.5295630140987002 length
00:04:58 - 6/41: Success rate: 6/6
00:04:58 - Mean path length for success exploration: 1.0275450853496455
00:04:58 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:04:58 - Scene graph of question 1b36e675-74ff-46ad-8caa-c33da46a5a67:
00:04:58 - Question: I want to host a dinner party on a summer evening, where should I set the table?
00:04:58 - Answer: On the table on the porch.
00:04:58 - Prediction: Consider setting the table near the window to enjoy the natural light and possibly a view, creating a pleasant atmosphere for a summer evening dinner party.
00:04:58 - 0-view_1.png:
00:04:58 - 	1: telephone 1
00:04:58 - 	4: pillow 1
00:04:58 - 0-view_6.png:
00:04:58 - 	2: nightstand 4
00:04:58 - 	3: lamp 3
00:04:58 - 	27: picture 1
00:04:58 - 0-view_3.png:
00:04:58 - 	7: bed 6
00:04:58 - 	8: pillow 3
00:04:58 - 	12: pillow 1
00:04:58 - 	13: pillow 1
00:04:58 - 	14: blanket 1
00:04:58 - 0-view_5.png:
00:04:58 - 	11: cabinet 5
00:04:58 - 	16: picture 3
00:04:58 - 	18: curtain 3
00:04:58 - 	21: picture 1
00:04:58 - 	23: tv 1
00:04:58 - 
========
Index: 6 Scene: 00880-Nfvxx8J5NCo
00:05:01 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:05:01 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:05:01 - 

Question id 1dcdd225-eba2-4ba1-97b6-c4cdc7ca4e9b initialization successful!
00:05:01 - 
== step: 0
00:05:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:05:03 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:05:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:05:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:05:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:05:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:05:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:05:13 - Step 0, update snapshots, 24 objects, 6 snapshots
00:05:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:05:16 - Prefiltering selected classes: ['cabinet', 'counter', 'shelf', 'sink']
00:05:16 - Prefiltering snapshot: 6 -> 4
00:05:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:05:20 - Response: [snapshot 0]
Reason: [You can keep the new knife in the kitchen cabinet.]
00:05:20 - Prediction: snapshot, 0
00:05:20 - The index of target snapshot 1
00:05:20 - Pred_target_class: cabinet tissue box refrigerator picture sink paper bag
00:05:20 - Next choice Snapshot of 0-view_4.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:05:20 - Current position: [    -8.5166     0.18086    -0.04755], 1.044
00:05:22 - 
== step: 1
00:05:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:05:25 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:05:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:05:27 - Step 1, update snapshots, 27 objects, 8 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:05:28 - Current position: [    -8.1166     0.18086     0.05245], 1.456
00:05:31 - Question id 1dcdd225-eba2-4ba1-97b6-c4cdc7ca4e9b finished after arriving at target!
00:05:31 - Question id 1dcdd225-eba2-4ba1-97b6-c4cdc7ca4e9b finish successfully, 1.456341213452821 length
00:05:31 - 7/41: Success rate: 7/7
00:05:31 - Mean path length for success exploration: 1.0888016750786706
00:05:31 - Filtered snapshots/Total snapshots/Total frames: 4/8/10
00:05:31 - Scene graph of question 1dcdd225-eba2-4ba1-97b6-c4cdc7ca4e9b:
00:05:31 - Question: where can I keep a new knife I got?
00:05:31 - Answer: there is a knife holder in the kitchen counter next to the gas stove.
00:05:31 - Prediction: You can keep the new knife in the kitchen cabinet.
00:05:31 - 0-view_0.png:
00:05:31 - 	1: couch 6
00:05:31 - 	2: coffee table 2
00:05:31 - 	3: book 2
00:05:31 - 	4: mat 1
00:05:31 - 0-view_6.png:
00:05:31 - 	8: fan 2
00:05:31 - 0-view_2.png:
00:05:31 - 	10: microwave 1
00:05:31 - 	11: stool 1
00:05:31 - 	12: trash bin 1
00:05:31 - 	13: counter 1
00:05:31 - 0-view_4.png:
00:05:31 - 	14: sink 5
00:05:31 - 	15: refrigerator 5
00:05:31 - 	25: paper bag 1
00:05:31 - 	27: tissue box 1
00:05:31 - 	32: cabinet 2
00:05:31 - 0-view_3.png:
00:05:31 - 	16: stool 3
00:05:31 - 	17: stool 3
00:05:31 - 	18: stool 2
00:05:31 - 	19: microwave 3
00:05:31 - 	20: picture 3
00:05:31 - 	21: shelf 2
00:05:31 - 	23: stove 3
00:05:31 - 1-view_1.png:
00:05:31 - 	29: picture 3
00:05:31 - 	52: picture 2
00:05:31 - 0-view_5.png:
00:05:31 - 	37: shelf 1
00:05:31 - 	38: picture 1
00:05:31 - 1-view_0.png:
00:05:31 - 	47: cabinet 1
00:05:31 - 	50: cabinet 1
00:05:31 - 
========
Index: 7 Scene: 00824-Dd4bFSTQ8gi
00:05:34 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:05:34 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:05:35 - 

Question id 30dc765d-80c3-4901-9c69-65e6b48e254a initialization successful!
00:05:35 - 
== step: 0
00:05:35 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:05:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:05:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:05:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:05:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:05:43 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:05:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:05:45 - Step 0, update snapshots, 12 objects, 4 snapshots
00:05:47 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:05:47 - Prefiltering selected classes: ['chair', 'folded chair', 'potted plant', 'sofa chair']
00:05:47 - Prefiltering snapshot: 4 -> 3
00:05:51 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:05:51 - Response: [snapshot 1]
Reason: [The front door is white.]
00:05:51 - Prediction: snapshot, 1
00:05:51 - The index of target snapshot 1
00:05:51 - Pred_target_class: potted plant picture folded chair
00:05:51 - Next choice Snapshot of 0-view_0.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:05:51 - Current position: [     6.3147    0.068824      0.7036], 1.000
00:05:53 - 
== step: 1
00:05:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.03 seconds
00:05:55 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:05:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:05:57 - Step 1, update snapshots, 13 objects, 5 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:05:58 - Current position: [     6.1147    0.068824      0.5036], 1.283
00:06:00 - Question id 30dc765d-80c3-4901-9c69-65e6b48e254a finished after arriving at target!
00:06:00 - Question id 30dc765d-80c3-4901-9c69-65e6b48e254a finish successfully, 1.2828427124746191 length
00:06:00 - 8/41: Success rate: 8/8
00:06:00 - Mean path length for success exploration: 1.1130568047531642
00:06:00 - Filtered snapshots/Total snapshots/Total frames: 3/5/8
00:06:00 - Scene graph of question 30dc765d-80c3-4901-9c69-65e6b48e254a:
00:06:00 - Question: What color is the front door?
00:06:00 - Answer: Brown
00:06:00 - Prediction: The front door is white.
00:06:00 - 0-view_0.png:
00:06:00 - 	1: potted plant 3
00:06:00 - 	2: picture 3
00:06:00 - 	4: folded chair 1
00:06:00 - 0-view_5.png:
00:06:00 - 	3: bed 4
00:06:00 - 	7: plate 3
00:06:00 - 	9: folded chair 2
00:06:00 - 	11: plate 2
00:06:00 - 	12: table 2
00:06:00 - 	21: chair 1
00:06:00 - 0-view_3.png:
00:06:00 - 	8: sofa chair 1
00:06:00 - 	10: pillow 1
00:06:00 - 0-view_4.png:
00:06:00 - 	14: picture 1
00:06:00 - 1-view_1.png:
00:06:00 - 	23: coffee table 1
00:06:00 - 
========
Index: 8 Scene: 00824-Dd4bFSTQ8gi
00:06:03 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:06:03 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:06:04 - 

Question id 3a5be057-47d2-4f78-98a9-729ef19b3d8b initialization successful!
00:06:04 - 
== step: 0
00:06:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:06:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:06:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:06:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:06:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:06:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:06:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:06:14 - Step 0, update snapshots, 12 objects, 4 snapshots
00:06:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:06:16 - Prefiltering selected classes: ['pillow']
00:06:16 - Prefiltering snapshot: 4 -> 1
00:06:18 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:06:18 - Response: [snapshot 0]
Reason: [There are no pillows in the kitchen.]
00:06:18 - Prediction: snapshot, 0
00:06:18 - The index of target snapshot 2
00:06:18 - Pred_target_class: sofa chair pillow
00:06:18 - Next choice Snapshot of 0-view_3.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:06:18 - Current position: [     6.0147    0.068824      2.0036], 1.030
00:06:20 - 
== step: 1
00:06:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:06:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:06:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:06:25 - Step 1, update snapshots, 17 objects, 6 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:06:26 - Current position: [     5.1147    0.068824      2.4036], 2.014
00:06:29 - 
== step: 2
00:06:30 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:06:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:06:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:06:34 - Step 2, update snapshots, 19 objects, 6 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:06:35 - Current position: [     4.5147    0.068824      2.9036], 2.795
00:06:38 - Question id 3a5be057-47d2-4f78-98a9-729ef19b3d8b finished after arriving at target!
00:06:38 - Question id 3a5be057-47d2-4f78-98a9-729ef19b3d8b finish successfully, 2.795473761868976 length
00:06:38 - 9/41: Success rate: 9/9
00:06:38 - Mean path length for success exploration: 1.2999920222104766
00:06:38 - Filtered snapshots/Total snapshots/Total frames: 1/6/11
00:06:38 - Scene graph of question 3a5be057-47d2-4f78-98a9-729ef19b3d8b:
00:06:38 - Question: What color are the pillows in the kitchen?
00:06:38 - Answer: Blue
00:06:38 - Prediction: There are no pillows in the kitchen.
00:06:38 - 1-view_0.png:
00:06:38 - 	1: potted plant 3
00:06:38 - 	2: picture 3
00:06:38 - 0-view_5.png:
00:06:38 - 	3: bed 3
00:06:38 - 	7: plate 3
00:06:38 - 	9: folded chair 2
00:06:38 - 	11: plate 2
00:06:38 - 	12: table 2
00:06:38 - 	21: chair 1
00:06:38 - 0-view_0.png:
00:06:38 - 	4: folded chair 1
00:06:38 - 2-view_1.png:
00:06:38 - 	8: couch 8
00:06:38 - 	34: picture 3
00:06:38 - 	41: pillow 2
00:06:38 - 2-view_0.png:
00:06:38 - 	10: pillow 4
00:06:38 - 	23: fan 3
00:06:38 - 	25: coffee table 4
00:06:38 - 	26: chair 2
00:06:38 - 	28: potted plant 3
00:06:38 - 	38: pillow 2
00:06:38 - 0-view_4.png:
00:06:38 - 	14: picture 1
00:06:39 - 
========
Index: 9 Scene: 00876-mv2HUxq3B53
00:06:44 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:06:44 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:06:45 - 

Question id 45a5e082-a9e9-47ca-a036-dfafba92b16c initialization successful!
00:06:45 - 
== step: 0
00:06:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:06:48 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:06:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:06:51 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:06:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:06:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:06:55 - Step 0, update snapshots, 15 objects, 4 snapshots
00:06:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:06:57 - Prefiltering selected classes: ['cabinet']
00:06:57 - Prefiltering snapshot: 4 -> 1
00:07:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:07:01 - Response: [snapshot 0]
Reason: [The color of the countertop on the porch is not visible.]
00:07:01 - Prediction: snapshot, 0
00:07:01 - The index of target snapshot 0
00:07:01 - Pred_target_class: cabinet picture curtain picture tv
00:07:01 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:07:01 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:07:04 - 
== step: 1
00:07:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:07:07 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:07:08 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:07:08 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:07:11 - Question id 45a5e082-a9e9-47ca-a036-dfafba92b16c finished after arriving at target!
00:07:11 - Question id 45a5e082-a9e9-47ca-a036-dfafba92b16c finish successfully, 1.5295630140987002 length
00:07:11 - 10/41: Success rate: 10/10
00:07:11 - Mean path length for success exploration: 1.322949121399299
00:07:11 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:07:11 - Scene graph of question 45a5e082-a9e9-47ca-a036-dfafba92b16c:
00:07:11 - Question: What color is the countertop on the porch?
00:07:11 - Answer: Black
00:07:11 - Prediction: The color of the countertop on the porch is not visible.
00:07:11 - 0-view_1.png:
00:07:11 - 	1: telephone 1
00:07:11 - 	4: pillow 1
00:07:11 - 0-view_6.png:
00:07:11 - 	2: nightstand 4
00:07:11 - 	3: lamp 3
00:07:11 - 	27: picture 1
00:07:11 - 0-view_3.png:
00:07:11 - 	7: bed 6
00:07:11 - 	8: pillow 3
00:07:11 - 	12: pillow 1
00:07:11 - 	13: pillow 1
00:07:11 - 	14: blanket 1
00:07:11 - 0-view_5.png:
00:07:11 - 	11: cabinet 5
00:07:11 - 	16: picture 3
00:07:11 - 	18: curtain 3
00:07:11 - 	21: picture 1
00:07:11 - 	23: tv 1
00:07:11 - 
========
Index: 10 Scene: 00876-mv2HUxq3B53
00:07:16 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:07:16 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:07:17 - 

Question id 48d8aa7f-61cb-469b-9b6d-2549d1210281 initialization successful!
00:07:17 - 
== step: 0
00:07:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:07:20 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:07:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:25 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:07:27 - Step 0, update snapshots, 15 objects, 4 snapshots
00:07:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:07:29 - Prefiltering selected classes: ['bed', 'blanket', 'pillow']
00:07:29 - Prefiltering snapshot: 4 -> 2
00:07:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:07:34 - Response: [snapshot 1]
Reason: [The grey item on the bed is a pillow.]
00:07:34 - Prediction: snapshot, 1
00:07:34 - The index of target snapshot 3
00:07:34 - Pred_target_class: telephone pillow
00:07:34 - Next choice Snapshot of 0-view_1.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:07:34 - Current position: [    -7.5732    0.050354      7.3939], 0.985
00:07:37 - 
== step: 1
00:07:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:07:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:07:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:07:42 - Step 1, update snapshots, 15 objects, 5 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:07:42 - Current position: [    -7.5732    0.050354      7.3939], 0.985
00:07:44 - Question id 48d8aa7f-61cb-469b-9b6d-2549d1210281 finished after arriving at target!
00:07:44 - Question id 48d8aa7f-61cb-469b-9b6d-2549d1210281 finish successfully, 0.9848857801796105 length
00:07:44 - 11/41: Success rate: 11/11
00:07:44 - Mean path length for success exploration: 1.2922160903793272
00:07:44 - Filtered snapshots/Total snapshots/Total frames: 2/5/9
00:07:44 - Scene graph of question 48d8aa7f-61cb-469b-9b6d-2549d1210281:
00:07:44 - Question: What is the grey item on the bed?
00:07:44 - Answer: A blanket
00:07:44 - Prediction: The grey item on the bed is a pillow.
00:07:44 - 1-view_2.png:
00:07:44 - 	1: telephone 3
00:07:44 - 	12: pillow 4
00:07:44 - 0-view_6.png:
00:07:44 - 	2: nightstand 5
00:07:44 - 	3: lamp 5
00:07:44 - 	27: picture 1
00:07:44 - 0-view_1.png:
00:07:44 - 	4: pillow 1
00:07:44 - 0-view_3.png:
00:07:44 - 	7: bed 7
00:07:44 - 	8: pillow 5
00:07:44 - 	13: pillow 1
00:07:44 - 	14: blanket 1
00:07:44 - 0-view_5.png:
00:07:44 - 	11: cabinet 3
00:07:44 - 	16: picture 2
00:07:44 - 	18: curtain 2
00:07:44 - 	21: picture 1
00:07:44 - 	23: tv 1
00:07:44 - 
========
Index: 11 Scene: 00824-Dd4bFSTQ8gi
00:07:48 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:07:48 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:07:48 - 

Question id 4cc4212e-0db2-421f-8bb5-93817e58f9b4 initialization successful!
00:07:48 - 
== step: 0
00:07:48 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:50 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:07:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:07:53 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:07:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:07:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:07:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:07:58 - Step 0, update snapshots, 12 objects, 4 snapshots
00:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:00 - Prefiltering selected classes: ['table']
00:08:00 - Prefiltering snapshot: 4 -> 1
00:08:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:02 - Response: [snapshot 0]
Reason: [You can get drinking water from the kitchen sink.]
00:08:02 - Prediction: snapshot, 0
00:08:02 - The index of target snapshot 0
00:08:02 - Pred_target_class: bed plate plate table chair folded chair
00:08:02 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:08:02 - Current position: [     7.0147    0.068824      1.5036], 0.100
00:08:04 - Question id 4cc4212e-0db2-421f-8bb5-93817e58f9b4 finished after arriving at target!
00:08:04 - Question id 4cc4212e-0db2-421f-8bb5-93817e58f9b4 finish successfully, 0.1 length
00:08:04 - 12/41: Success rate: 12/12
00:08:04 - Mean path length for success exploration: 1.1928647495143834
00:08:04 - Filtered snapshots/Total snapshots/Total frames: 1/4/5
00:08:04 - Scene graph of question 4cc4212e-0db2-421f-8bb5-93817e58f9b4:
00:08:04 - Question: Where can I get drinking water in the kitchen?
00:08:04 - Answer: From water dispenser in the fridge
00:08:04 - Prediction: You can get drinking water from the kitchen sink.
00:08:04 - 0-view_0.png:
00:08:04 - 	1: potted plant 2
00:08:04 - 	2: picture 2
00:08:04 - 	4: folded chair 1
00:08:04 - 0-view_5.png:
00:08:04 - 	3: bed 3
00:08:04 - 	7: plate 3
00:08:04 - 	9: folded chair 2
00:08:04 - 	11: plate 2
00:08:04 - 	12: table 2
00:08:04 - 	21: chair 1
00:08:04 - 0-view_3.png:
00:08:04 - 	8: sofa chair 1
00:08:04 - 	10: pillow 1
00:08:04 - 0-view_4.png:
00:08:04 - 	14: picture 1
00:08:04 - 
========
Index: 12 Scene: 00824-Dd4bFSTQ8gi
00:08:07 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:08:07 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:08:08 - 

Question id 4dbd213e-56cd-481a-8ff5-ed9a8d636dbc initialization successful!
00:08:08 - 
== step: 0
00:08:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:08:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:08:11 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:08:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:08:14 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:08:15 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:08:17 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:08:18 - Step 0, update snapshots, 12 objects, 4 snapshots
00:08:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:20 - Prefiltering selected classes: ['table']
00:08:20 - Prefiltering snapshot: 4 -> 1
00:08:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:23 - Response: [snapshot 0]
Reason: [It's not possible to determine if the light above the sink is turned on.]
00:08:23 - Prediction: snapshot, 0
00:08:23 - The index of target snapshot 0
00:08:23 - Pred_target_class: bed plate plate table chair folded chair
00:08:23 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:08:23 - Current position: [     7.0147    0.068824      1.5036], 0.100
00:08:25 - Question id 4dbd213e-56cd-481a-8ff5-ed9a8d636dbc finished after arriving at target!
00:08:25 - Question id 4dbd213e-56cd-481a-8ff5-ed9a8d636dbc finish successfully, 0.1 length
00:08:25 - 13/41: Success rate: 13/13
00:08:25 - Mean path length for success exploration: 1.1087982303209691
00:08:25 - Filtered snapshots/Total snapshots/Total frames: 1/4/5
00:08:25 - Scene graph of question 4dbd213e-56cd-481a-8ff5-ed9a8d636dbc:
00:08:25 - Question: Is the light above the sink turned on?
00:08:25 - Answer: Yes
00:08:25 - Prediction: It's not possible to determine if the light above the sink is turned on.
00:08:25 - 0-view_0.png:
00:08:25 - 	1: potted plant 2
00:08:25 - 	2: picture 2
00:08:25 - 	4: folded chair 1
00:08:25 - 0-view_5.png:
00:08:25 - 	3: bed 3
00:08:25 - 	7: plate 3
00:08:25 - 	9: folded chair 2
00:08:25 - 	11: plate 2
00:08:25 - 	12: table 2
00:08:25 - 	21: chair 1
00:08:25 - 0-view_3.png:
00:08:25 - 	8: sofa chair 1
00:08:25 - 	10: pillow 1
00:08:25 - 0-view_4.png:
00:08:25 - 	14: picture 1
00:08:25 - 
========
Index: 13 Scene: 00880-Nfvxx8J5NCo
00:08:28 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:08:28 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:08:28 - 

Question id 67cd7145-4b1f-4b2a-a698-8e4738cb7c41 initialization successful!
00:08:28 - 
== step: 0
00:08:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:08:30 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:08:32 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:08:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:08:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:08:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:08:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:08:40 - Step 0, update snapshots, 24 objects, 6 snapshots
00:08:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:43 - Prefiltering selected classes: ['refrigerator', 'cabinet', 'shelf', 'counter', 'microwave', 'paper bag']
00:08:43 - Prefiltering snapshot: 6 -> 4
00:08:46 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:08:46 - Response: [snapshot 1]
Reason: [You can keep a couple of apples on the kitchen counter.]
00:08:46 - Prediction: snapshot, 1
00:08:46 - The index of target snapshot 2
00:08:46 - Pred_target_class: microwave shelf stove picture stool stool stool
00:08:46 - Next choice Snapshot of 0-view_3.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:08:47 - Current position: [    -9.0166     0.18086     0.35245], 0.860
00:08:49 - Question id 67cd7145-4b1f-4b2a-a698-8e4738cb7c41 finished after arriving at target!
00:08:49 - Question id 67cd7145-4b1f-4b2a-a698-8e4738cb7c41 finish successfully, 0.8602325267042628 length
00:08:49 - 14/41: Success rate: 14/14
00:08:49 - Mean path length for success exploration: 1.09104353720549
00:08:49 - Filtered snapshots/Total snapshots/Total frames: 4/6/7
00:08:49 - Scene graph of question 67cd7145-4b1f-4b2a-a698-8e4738cb7c41:
00:08:49 - Question: where can I keep a couple of apples?
00:08:49 - Answer: on the fruit basket in the kitchen counter.
00:08:49 - Prediction: You can keep a couple of apples on the kitchen counter.
00:08:49 - 0-view_0.png:
00:08:49 - 	1: couch 4
00:08:49 - 	2: coffee table 2
00:08:49 - 	3: book 2
00:08:49 - 	4: mat 1
00:08:49 - 0-view_6.png:
00:08:49 - 	8: fan 2
00:08:49 - 0-view_2.png:
00:08:49 - 	10: microwave 1
00:08:49 - 	11: stool 1
00:08:49 - 	12: trash bin 1
00:08:49 - 	13: counter 1
00:08:49 - 0-view_4.png:
00:08:49 - 	14: sink 4
00:08:49 - 	15: refrigerator 3
00:08:49 - 	25: paper bag 1
00:08:49 - 	27: tissue box 1
00:08:49 - 	29: picture 2
00:08:49 - 	32: cabinet 1
00:08:49 - 0-view_3.png:
00:08:49 - 	16: stool 3
00:08:49 - 	17: stool 2
00:08:49 - 	18: stool 2
00:08:49 - 	19: microwave 2
00:08:49 - 	20: picture 2
00:08:49 - 	21: shelf 2
00:08:49 - 	23: stove 2
00:08:49 - 0-view_5.png:
00:08:49 - 	37: shelf 1
00:08:49 - 	38: picture 1
00:08:49 - 
========
Index: 14 Scene: 00848-ziup5kvtCCR
00:08:52 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:08:52 - Load scene 00848-ziup5kvtCCR successfully with semantic texture
00:08:52 - 

Question id 6852b358-4820-471d-9263-d32ef0cecd0b initialization successful!
00:08:52 - 
== step: 0
00:08:53 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.15 seconds
00:08:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:08:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:08:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:09:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:09:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:09:03 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:09:04 - Step 0, update snapshots, 25 objects, 7 snapshots
00:09:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:09:07 - Prefiltering selected classes: ['couch', 'cabinet', 'mirror', 'potted plant', 'tv']
00:09:07 - Prefiltering snapshot: 7 -> 5
00:09:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:09:11 - Response: [snapshot 0]
Reason: [The wreath is not visible.]
00:09:11 - Prediction: snapshot, 0
00:09:11 - The index of target snapshot 0
00:09:11 - Pred_target_class: lamp coffee table potted plant pillow pillow pillow pillow couch
00:09:11 - Next choice Snapshot of 0-view_0.png
00:09:11 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 1 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:09:11 - Current position: [    0.21692    0.021223      7.1057], 0.000
00:09:13 - Question id 6852b358-4820-471d-9263-d32ef0cecd0b finished after arriving at target!
00:09:13 - Question id 6852b358-4820-471d-9263-d32ef0cecd0b finish successfully, 0.0 length
00:09:13 - 15/41: Success rate: 15/15
00:09:13 - Mean path length for success exploration: 1.0183073013917907
00:09:13 - Filtered snapshots/Total snapshots/Total frames: 5/7/7
00:09:13 - Scene graph of question 6852b358-4820-471d-9263-d32ef0cecd0b:
00:09:13 - Question: Where is the wreath?
00:09:13 - Answer: Hanging on the front door.
00:09:13 - Prediction: The wreath is not visible.
00:09:13 - 0-view_0.png:
00:09:13 - 	1: lamp 1
00:09:13 - 	2: pillow 3
00:09:13 - 	4: couch 2
00:09:13 - 	5: coffee table 1
00:09:13 - 	6: potted plant 1
00:09:13 - 	7: pillow 2
00:09:13 - 	8: pillow 2
00:09:13 - 	9: pillow 1
00:09:13 - 0-view_2.png:
00:09:13 - 	3: pillow 3
00:09:13 - 	18: couch 2
00:09:13 - 0-view_1.png:
00:09:13 - 	10: coffee table 3
00:09:13 - 	11: sofa chair 3
00:09:13 - 	14: pillow 1
00:09:13 - 0-view_6.png:
00:09:13 - 	21: cabinet 3
00:09:13 - 	25: tv 2
00:09:13 - 	26: potted plant 3
00:09:13 - 0-view_3.png:
00:09:13 - 	24: mirror 1
00:09:13 - 0-view_4.png:
00:09:13 - 	28: clock 2
00:09:13 - 	29: bottle 2
00:09:13 - 0-view_5.png:
00:09:13 - 	30: mirror 2
00:09:13 - 	32: clock 2
00:09:13 - 	35: lamp 2
00:09:13 - 	39: curtain 1
00:09:13 - 	40: candle 1
00:09:13 - 	41: potted plant 1
00:09:13 - 
========
Index: 15 Scene: 00824-Dd4bFSTQ8gi
00:09:16 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:09:16 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:09:17 - 

Question id 6d132959-fd48-4fef-a736-4e5853849547 initialization successful!
00:09:17 - 
== step: 0
00:09:17 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:09:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:09:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:09:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:09:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:09:25 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:09:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:09:27 - Step 0, update snapshots, 12 objects, 4 snapshots
00:09:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:09:29 - Prefiltering selected classes: ['sofa chair', 'pillow', 'bed']
00:09:29 - Prefiltering snapshot: 4 -> 2
00:09:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:09:32 - Response: [snapshot 1]
Reason: [You can warm up on the sofa with pillows.]
00:09:32 - Prediction: snapshot, 1
00:09:32 - The index of target snapshot 2
00:09:32 - Pred_target_class: sofa chair pillow
00:09:32 - Next choice Snapshot of 0-view_3.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:09:32 - Current position: [     6.0147    0.068824      2.0036], 1.030
00:09:35 - 
== step: 1
00:09:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:09:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:09:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:09:39 - Step 1, update snapshots, 17 objects, 6 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:09:41 - Current position: [     5.1147    0.068824      2.4036], 2.014
00:09:43 - 
== step: 2
00:09:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:09:46 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:09:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:09:48 - Step 2, update snapshots, 19 objects, 6 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:09:50 - Current position: [     4.5147    0.068824      2.9036], 2.795
00:09:53 - Question id 6d132959-fd48-4fef-a736-4e5853849547 finished after arriving at target!
00:09:53 - Question id 6d132959-fd48-4fef-a736-4e5853849547 finish successfully, 2.795473761868976 length
00:09:53 - 16/41: Success rate: 16/16
00:09:53 - Mean path length for success exploration: 1.1293802051716149
00:09:53 - Filtered snapshots/Total snapshots/Total frames: 2/6/11
00:09:53 - Scene graph of question 6d132959-fd48-4fef-a736-4e5853849547:
00:09:53 - Question: Where can I warm up?
00:09:53 - Answer: Next to the fireplace
00:09:53 - Prediction: You can warm up on the sofa with pillows.
00:09:53 - 1-view_0.png:
00:09:53 - 	1: potted plant 3
00:09:53 - 	2: picture 3
00:09:53 - 0-view_5.png:
00:09:53 - 	3: bed 3
00:09:53 - 	7: plate 3
00:09:53 - 	9: folded chair 2
00:09:53 - 	11: plate 2
00:09:53 - 	12: table 2
00:09:53 - 	21: chair 1
00:09:53 - 0-view_0.png:
00:09:53 - 	4: folded chair 1
00:09:53 - 2-view_1.png:
00:09:53 - 	8: couch 8
00:09:53 - 	34: picture 3
00:09:53 - 	41: pillow 2
00:09:53 - 2-view_0.png:
00:09:53 - 	10: pillow 4
00:09:53 - 	23: fan 3
00:09:53 - 	25: coffee table 4
00:09:53 - 	26: chair 2
00:09:53 - 	28: potted plant 3
00:09:53 - 	38: pillow 2
00:09:53 - 0-view_4.png:
00:09:53 - 	14: picture 1
00:09:53 - 
========
Index: 16 Scene: 00824-Dd4bFSTQ8gi
00:09:56 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:09:56 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:09:56 - 

Question id 7ebac357-a338-4ce0-975a-62141e90a3c3 initialization successful!
00:09:56 - 
== step: 0
00:09:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:09:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:10:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:10:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:10:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:10:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:10:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:10:06 - Step 0, update snapshots, 12 objects, 4 snapshots
00:10:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:10:08 - Prefiltering selected classes: ['table']
00:10:08 - Prefiltering snapshot: 4 -> 1
00:10:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:10:11 - Response: [snapshot 0]
Reason: [The microwave is not visible.]
00:10:11 - Prediction: snapshot, 0
00:10:11 - The index of target snapshot 0
00:10:11 - Pred_target_class: bed plate plate table chair folded chair
00:10:11 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:10:11 - Current position: [     7.0147    0.068824      1.5036], 0.100
00:10:13 - Question id 7ebac357-a338-4ce0-975a-62141e90a3c3 finished after arriving at target!
00:10:13 - Question id 7ebac357-a338-4ce0-975a-62141e90a3c3 finish successfully, 0.1 length
00:10:13 - 17/41: Success rate: 17/17
00:10:13 - Mean path length for success exploration: 1.0688284283968141
00:10:13 - Filtered snapshots/Total snapshots/Total frames: 1/4/5
00:10:13 - Scene graph of question 7ebac357-a338-4ce0-975a-62141e90a3c3:
00:10:13 - Question: Where is the microwave?
00:10:13 - Answer: Above the stovetop
00:10:13 - Prediction: The microwave is not visible.
00:10:13 - 0-view_0.png:
00:10:13 - 	1: potted plant 2
00:10:13 - 	2: picture 2
00:10:13 - 	4: folded chair 1
00:10:13 - 0-view_5.png:
00:10:13 - 	3: bed 3
00:10:13 - 	7: plate 3
00:10:13 - 	9: folded chair 2
00:10:13 - 	11: plate 2
00:10:13 - 	12: table 2
00:10:13 - 	21: chair 1
00:10:13 - 0-view_3.png:
00:10:13 - 	8: sofa chair 1
00:10:13 - 	10: pillow 1
00:10:13 - 0-view_4.png:
00:10:13 - 	14: picture 1
00:10:13 - 
========
Index: 17 Scene: 00880-Nfvxx8J5NCo
00:10:16 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:10:16 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:10:17 - 

Question id 90ab6389-d85e-42ad-b44a-af4849da2631 initialization successful!
00:10:17 - 
== step: 0
00:10:17 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:10:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:10:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:10:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:10:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:10:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:10:27 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:10:29 - Step 0, update snapshots, 24 objects, 6 snapshots
00:10:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:10:32 - Prefiltering selected classes: ['picture', 'shelf', 'cabinet', 'counter']
00:10:32 - Prefiltering snapshot: 6 -> 4
00:10:36 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:10:36 - Response: [snapshot 2]
Reason: [There is no clock visible.]
00:10:36 - Prediction: snapshot, 2
00:10:36 - The index of target snapshot 3
00:10:36 - Pred_target_class: shelf picture
00:10:36 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:10:36 - Current position: [    -8.8166     0.18086     -1.0476], 0.990
00:10:38 - 
== step: 1
00:10:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:10:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:10:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:10:43 - Step 1, update snapshots, 28 objects, 7 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:10:44 - Current position: [    -8.3166     0.18086     -1.8476], 1.933
00:10:47 - 
== step: 2
00:10:48 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:10:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:10:50 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:10:51 - Step 2, update snapshots, 29 objects, 9 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:10:52 - Current position: [    -8.0166     0.18086     -2.0476], 2.294
00:10:55 - Question id 90ab6389-d85e-42ad-b44a-af4849da2631 finished after arriving at target!
00:10:55 - Question id 90ab6389-d85e-42ad-b44a-af4849da2631 finish successfully, 2.293902734413226 length
00:10:55 - 18/41: Success rate: 18/18
00:10:55 - Mean path length for success exploration: 1.1368881120643926
00:10:55 - Filtered snapshots/Total snapshots/Total frames: 4/9/13
00:10:55 - Scene graph of question 90ab6389-d85e-42ad-b44a-af4849da2631:
00:10:55 - Question: where is the clock?
00:10:55 - Answer: in the living room hallway next to the television
00:10:55 - Prediction: There is no clock visible.
00:10:55 - 0-view_0.png:
00:10:55 - 	1: couch 9
00:10:55 - 	2: coffee table 4
00:10:55 - 	3: book 4
00:10:55 - 	4: mat 1
00:10:55 - 0-view_6.png:
00:10:55 - 	8: fan 2
00:10:55 - 0-view_2.png:
00:10:55 - 	10: microwave 1
00:10:55 - 	11: stool 1
00:10:55 - 	12: trash bin 1
00:10:55 - 	13: counter 1
00:10:55 - 0-view_4.png:
00:10:55 - 	14: sink 4
00:10:55 - 	15: refrigerator 4
00:10:55 - 	25: paper bag 6
00:10:55 - 	27: tissue box 2
00:10:55 - 	32: cabinet 1
00:10:55 - 0-view_3.png:
00:10:55 - 	16: stool 3
00:10:55 - 	17: stool 2
00:10:55 - 	18: stool 2
00:10:55 - 	19: microwave 2
00:10:55 - 	20: picture 3
00:10:55 - 	21: shelf 2
00:10:55 - 	23: stove 2
00:10:55 - 1-view_0.png:
00:10:55 - 	29: picture 4
00:10:55 - 	46: picture 3
00:10:55 - 1-view_2.png:
00:10:55 - 	37: shelf 6
00:10:55 - 	38: picture 2
00:10:55 - 	55: picture 4
00:10:55 - 1-view_1.png:
00:10:55 - 	52: fan 1
00:10:55 - 	56: picture 3
00:10:55 - 2-view_0.png:
00:10:55 - 	71: book 1
00:10:55 - 
========
Index: 18 Scene: 00835-q3zU7Yy5E5s
00:10:58 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:10:58 - Load scene 00835-q3zU7Yy5E5s successfully with semantic texture
00:10:58 - 

Question id 911693d9-2d28-4ff2-83a9-c67b83753831 initialization successful!
00:10:58 - 
== step: 0
00:10:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:03 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:06 - Step 0, update snapshots, 2 objects, 2 snapshots
00:11:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:07 - Prefiltering selected classes: ['washing machine', 'bucket']
00:11:07 - Prefiltering snapshot: 2 -> 2
00:11:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:11 - Response: [snapshot 0]
Reason: [I can't see what's outside the window from here.]
00:11:11 - Prediction: snapshot, 0
00:11:11 - The index of target snapshot 0
00:11:11 - Pred_target_class: washing machine
00:11:11 - Next choice Snapshot of 0-view_0.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:11:11 - Current position: [    0.27412     0.03522    -0.90346], 0.943
00:11:12 - Question id 911693d9-2d28-4ff2-83a9-c67b83753831 finished after arriving at target!
00:11:12 - Question id 911693d9-2d28-4ff2-83a9-c67b83753831 finish successfully, 0.9433981132056604 length
00:11:12 - 19/41: Success rate: 19/19
00:11:12 - Mean path length for success exploration: 1.1267044279139329
00:11:12 - Filtered snapshots/Total snapshots/Total frames: 2/2/3
00:11:12 - Scene graph of question 911693d9-2d28-4ff2-83a9-c67b83753831:
00:11:12 - Question: What can be seen through the window in the living room?
00:11:12 - Answer: Trees and hills
00:11:12 - Prediction: I can't see what's outside the window from here.
00:11:12 - 0-view_0.png:
00:11:12 - 	1: washing machine 1
00:11:12 - 0-view_5.png:
00:11:12 - 	2: bucket 2
00:11:12 - 
========
Index: 19 Scene: 00835-q3zU7Yy5E5s
00:11:15 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:11:15 - Load scene 00835-q3zU7Yy5E5s successfully with semantic texture
00:11:15 - 

Question id 9b2d06e5-ca78-4519-a9ca-75c06209b770 initialization successful!
00:11:15 - 
== step: 0
00:11:16 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:20 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:11:23 - Step 0, update snapshots, 2 objects, 2 snapshots
00:11:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:25 - Prefiltering selected classes: ['bucket', 'washing machine']
00:11:25 - Prefiltering snapshot: 2 -> 2
00:11:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:28 - Response: [snapshot 0]
Reason: [The snapshot does not show a fireplace.]
00:11:28 - Prediction: snapshot, 0
00:11:28 - The index of target snapshot 0
00:11:28 - Pred_target_class: washing machine
00:11:28 - Next choice Snapshot of 0-view_0.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:11:28 - Current position: [    0.27412     0.03522    -0.90346], 0.943
00:11:30 - Question id 9b2d06e5-ca78-4519-a9ca-75c06209b770 finished after arriving at target!
00:11:30 - Question id 9b2d06e5-ca78-4519-a9ca-75c06209b770 finish successfully, 0.9433981132056604 length
00:11:30 - 20/41: Success rate: 20/20
00:11:30 - Mean path length for success exploration: 1.1175391121785192
00:11:30 - Filtered snapshots/Total snapshots/Total frames: 2/2/3
00:11:30 - Scene graph of question 9b2d06e5-ca78-4519-a9ca-75c06209b770:
00:11:30 - Question: Where is the fireplace?
00:11:30 - Answer: In the living room, to the right of the radiator and window
00:11:30 - Prediction: The snapshot does not show a fireplace.
00:11:30 - 0-view_0.png:
00:11:30 - 	1: washing machine 1
00:11:30 - 0-view_5.png:
00:11:30 - 	2: bucket 2
00:11:30 - 
========
Index: 20 Scene: 00848-ziup5kvtCCR
00:11:33 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:11:33 - Load scene 00848-ziup5kvtCCR successfully with semantic texture
00:11:33 - 

Question id a36ab369-6f78-4311-a943-b6862cd28b55 initialization successful!
00:11:33 - 
== step: 0
00:11:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.15 seconds
00:11:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:11:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:11:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:11:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:11:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:11:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:11:45 - Step 0, update snapshots, 25 objects, 7 snapshots
00:11:47 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:47 - Prefiltering selected classes: ['clock', 'mirror', 'curtain']
00:11:47 - Prefiltering snapshot: 7 -> 3
00:11:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:11:50 - Response: [snapshot 0]
Reason: [A mirror is hanging on the wall in the living room.]
00:11:50 - Prediction: snapshot, 0
00:11:50 - The index of target snapshot 1
00:11:50 - Pred_target_class: clock lamp mirror candle curtain potted plant
00:11:50 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:11:51 - Current position: [    0.21692    0.021223      7.3057], 0.200
00:11:53 - Question id a36ab369-6f78-4311-a943-b6862cd28b55 finished after arriving at target!
00:11:53 - Question id a36ab369-6f78-4311-a943-b6862cd28b55 finish successfully, 0.2 length
00:11:53 - 21/41: Success rate: 21/21
00:11:53 - Mean path length for success exploration: 1.0738467735033517
00:11:53 - Filtered snapshots/Total snapshots/Total frames: 3/7/7
00:11:53 - Scene graph of question a36ab369-6f78-4311-a943-b6862cd28b55:
00:11:53 - Question: What is hanging on the wall in the living room?
00:11:53 - Answer: A clock
00:11:53 - Prediction: A mirror is hanging on the wall in the living room.
00:11:53 - 0-view_0.png:
00:11:53 - 	1: lamp 1
00:11:53 - 	2: pillow 3
00:11:53 - 	4: couch 2
00:11:53 - 	5: coffee table 1
00:11:53 - 	6: potted plant 1
00:11:53 - 	7: pillow 2
00:11:53 - 	8: pillow 2
00:11:53 - 	9: pillow 1
00:11:53 - 0-view_2.png:
00:11:53 - 	3: pillow 3
00:11:53 - 	18: couch 2
00:11:53 - 0-view_1.png:
00:11:53 - 	10: coffee table 3
00:11:53 - 	11: sofa chair 3
00:11:53 - 	14: pillow 1
00:11:53 - 0-view_6.png:
00:11:53 - 	21: cabinet 3
00:11:53 - 	25: tv 2
00:11:53 - 	26: potted plant 3
00:11:53 - 0-view_3.png:
00:11:53 - 	24: mirror 1
00:11:53 - 0-view_4.png:
00:11:53 - 	28: clock 2
00:11:53 - 	29: bottle 2
00:11:53 - 0-view_5.png:
00:11:53 - 	30: mirror 2
00:11:53 - 	32: clock 2
00:11:53 - 	35: lamp 2
00:11:53 - 	39: curtain 1
00:11:53 - 	40: candle 1
00:11:53 - 	41: potted plant 1
00:11:53 - 
========
Index: 21 Scene: 00880-Nfvxx8J5NCo
00:11:56 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:11:56 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:11:56 - 

Question id a5c5bb29-700a-4ef5-b17d-aaa47bb0ef3f initialization successful!
00:11:56 - 
== step: 0
00:11:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:11:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:12:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:12:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:12:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:12:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:12:07 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:12:08 - Step 0, update snapshots, 24 objects, 6 snapshots
00:12:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:12:11 - Prefiltering selected classes: ['counter', 'stool', 'sink', 'shelf', 'stove']
00:12:11 - Prefiltering snapshot: 6 -> 4
00:12:15 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:12:15 - Response: [snapshot 2]
Reason: [There is a shelf between the fruit bowl and knife set.]
00:12:15 - Prediction: snapshot, 2
00:12:15 - The index of target snapshot 3
00:12:15 - Pred_target_class: shelf picture
00:12:15 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:12:15 - Current position: [    -8.8166     0.18086     -1.0476], 0.990
00:12:17 - 
== step: 1
00:12:18 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:12:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:12:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:12:22 - Step 1, update snapshots, 28 objects, 7 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:12:23 - Current position: [    -8.3166     0.18086     -1.8476], 1.933
00:12:26 - 
== step: 2
00:12:27 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:12:28 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:12:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:12:30 - Step 2, update snapshots, 29 objects, 9 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:12:32 - Current position: [    -8.0166     0.18086     -2.0476], 2.294
00:12:34 - Question id a5c5bb29-700a-4ef5-b17d-aaa47bb0ef3f finished after arriving at target!
00:12:34 - Question id a5c5bb29-700a-4ef5-b17d-aaa47bb0ef3f finish successfully, 2.293902734413226 length
00:12:34 - 22/41: Success rate: 22/22
00:12:34 - Mean path length for success exploration: 1.1293038626356187
00:12:34 - Filtered snapshots/Total snapshots/Total frames: 4/9/13
00:12:34 - Scene graph of question a5c5bb29-700a-4ef5-b17d-aaa47bb0ef3f:
00:12:34 - Question: what is between the fruit bowl and knife set?
00:12:34 - Answer: a container of spices
00:12:34 - Prediction: There is a shelf between the fruit bowl and knife set.
00:12:34 - 0-view_0.png:
00:12:34 - 	1: couch 9
00:12:34 - 	2: coffee table 4
00:12:34 - 	3: book 4
00:12:34 - 	4: mat 1
00:12:34 - 0-view_6.png:
00:12:34 - 	8: fan 2
00:12:34 - 0-view_2.png:
00:12:34 - 	10: microwave 1
00:12:34 - 	11: stool 1
00:12:34 - 	12: trash bin 1
00:12:34 - 	13: counter 1
00:12:34 - 0-view_4.png:
00:12:34 - 	14: sink 4
00:12:34 - 	15: refrigerator 4
00:12:34 - 	25: paper bag 6
00:12:34 - 	27: tissue box 2
00:12:34 - 	32: cabinet 1
00:12:34 - 0-view_3.png:
00:12:34 - 	16: stool 3
00:12:34 - 	17: stool 2
00:12:34 - 	18: stool 2
00:12:34 - 	19: microwave 2
00:12:34 - 	20: picture 3
00:12:34 - 	21: shelf 2
00:12:34 - 	23: stove 2
00:12:34 - 1-view_0.png:
00:12:34 - 	29: picture 4
00:12:34 - 	46: picture 3
00:12:34 - 1-view_2.png:
00:12:34 - 	37: shelf 6
00:12:34 - 	38: picture 2
00:12:34 - 	55: picture 4
00:12:34 - 1-view_1.png:
00:12:34 - 	52: fan 1
00:12:34 - 	56: picture 3
00:12:34 - 2-view_0.png:
00:12:34 - 	71: book 1
00:12:34 - 
========
Index: 22 Scene: 00824-Dd4bFSTQ8gi
00:12:37 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:12:37 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:12:38 - 

Question id a605c40f-96e7-4bec-a1cb-6d48e88e39cd initialization successful!
00:12:38 - 
== step: 0
00:12:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:12:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:12:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:12:43 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:12:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:12:46 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:12:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:12:48 - Step 0, update snapshots, 12 objects, 4 snapshots
00:12:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:12:50 - Prefiltering selected classes: ['picture', 'potted plant', 'plate']
00:12:50 - Prefiltering snapshot: 4 -> 3
00:12:53 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:12:53 - Response: [snapshot 2]
Reason: [There is a picture above the wooden table in the living room.]
00:12:53 - Prediction: snapshot, 2
00:12:53 - The index of target snapshot 3
00:12:53 - Pred_target_class: picture
00:12:53 - Next choice Snapshot of 0-view_4.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:12:53 - Current position: [     7.2147    0.068824      2.4036], 0.949
00:12:55 - 
== step: 1
00:12:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:12:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:12:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:12:59 - Step 1, update snapshots, 13 objects, 5 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:13:01 - Current position: [     7.5147    0.068824      3.0036], 1.620
00:13:03 - Question id a605c40f-96e7-4bec-a1cb-6d48e88e39cd finished after arriving at target!
00:13:03 - Question id a605c40f-96e7-4bec-a1cb-6d48e88e39cd finish successfully, 1.619503691300451 length
00:13:03 - 23/41: Success rate: 23/23
00:13:03 - Mean path length for success exploration: 1.1506168986645244
00:13:03 - Filtered snapshots/Total snapshots/Total frames: 3/5/8
00:13:03 - Scene graph of question a605c40f-96e7-4bec-a1cb-6d48e88e39cd:
00:13:03 - Question: What is above the wooden table in the living room?
00:13:03 - Answer: A blue, white, and orange painting
00:13:03 - Prediction: There is a picture above the wooden table in the living room.
00:13:03 - 0-view_0.png:
00:13:03 - 	1: potted plant 2
00:13:03 - 	2: picture 2
00:13:03 - 	4: folded chair 1
00:13:03 - 0-view_5.png:
00:13:03 - 	3: dining table 4
00:13:03 - 	7: plate 3
00:13:03 - 	9: folded chair 3
00:13:03 - 	11: plate 3
00:13:03 - 	12: table 2
00:13:03 - 	21: chair 2
00:13:03 - 0-view_3.png:
00:13:03 - 	8: sofa chair 1
00:13:03 - 	10: pillow 1
00:13:03 - 0-view_4.png:
00:13:03 - 	14: picture 1
00:13:03 - 1-view_2.png:
00:13:03 - 	22: sofa chair 2
00:13:03 - 
========
Index: 23 Scene: 00824-Dd4bFSTQ8gi
00:13:06 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:13:06 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:13:07 - 

Question id ae19adeb-498a-4814-b955-e0af05623f9b initialization successful!
00:13:07 - 
== step: 0
00:13:07 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:13:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:13:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:13:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:13:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:13:14 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:13:16 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:13:17 - Step 0, update snapshots, 12 objects, 4 snapshots
00:13:19 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:13:19 - Prefiltering selected classes: ['table']
00:13:19 - Prefiltering snapshot: 4 -> 1
00:13:21 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:13:21 - Response: [snapshot 0]
Reason: [You can find recipes online on websites, cooking blogs, or apps dedicated to cooking and meal planning. Additionally, cookbooks are a great resource for recipes.]
00:13:21 - Prediction: snapshot, 0
00:13:21 - The index of target snapshot 0
00:13:21 - Pred_target_class: bed plate plate table chair folded chair
00:13:21 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:13:21 - Current position: [     7.0147    0.068824      1.5036], 0.100
00:13:24 - Question id ae19adeb-498a-4814-b955-e0af05623f9b finished after arriving at target!
00:13:24 - Question id ae19adeb-498a-4814-b955-e0af05623f9b finish successfully, 0.1 length
00:13:24 - 24/41: Success rate: 24/24
00:13:24 - Mean path length for success exploration: 1.1068411945535026
00:13:24 - Filtered snapshots/Total snapshots/Total frames: 1/4/5
00:13:24 - Scene graph of question ae19adeb-498a-4814-b955-e0af05623f9b:
00:13:24 - Question: Where can I get recipes for what to cook?
00:13:24 - Answer: The open cookbook on the kitchen counter top
00:13:24 - Prediction: You can find recipes online on websites, cooking blogs, or apps dedicated to cooking and meal planning. Additionally, cookbooks are a great resource for recipes.
00:13:24 - 0-view_0.png:
00:13:24 - 	1: potted plant 2
00:13:24 - 	2: picture 2
00:13:24 - 	4: folded chair 1
00:13:24 - 0-view_5.png:
00:13:24 - 	3: bed 3
00:13:24 - 	7: plate 3
00:13:24 - 	9: folded chair 2
00:13:24 - 	11: plate 2
00:13:24 - 	12: table 2
00:13:24 - 	21: chair 1
00:13:24 - 0-view_3.png:
00:13:24 - 	8: sofa chair 1
00:13:24 - 	10: pillow 1
00:13:24 - 0-view_4.png:
00:13:24 - 	14: picture 1
00:13:24 - 
========
Index: 24 Scene: 00880-Nfvxx8J5NCo
00:13:27 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:13:27 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:13:27 - 

Question id b05e7b30-6a4d-4381-9d05-a42ed0c90e30 initialization successful!
00:13:27 - 
== step: 0
00:13:28 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:13:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:13:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:13:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:13:35 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:13:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:13:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:13:39 - Step 0, update snapshots, 24 objects, 6 snapshots
00:13:42 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:13:42 - Prefiltering selected classes: ['coffee table', 'tissue box', 'paper bag', 'trash bin', 'book']
00:13:42 - Prefiltering snapshot: 6 -> 3
00:13:46 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:13:46 - Response: [snapshot 0]
Reason: [The table in the living room is not completely clean; there is a book on it.]
00:13:46 - Prediction: snapshot, 0
00:13:46 - The index of target snapshot 0
00:13:46 - Pred_target_class: couch coffee table book mat
00:13:46 - Next choice Snapshot of 0-view_0.png
RuntimeWarning: invalid value encountered in divide
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:13:46 - Current position: [    -9.8166     0.18086     -1.2476], 0.949
00:13:49 - 
== step: 1
00:13:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:13:51 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:13:53 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:13:53 - Step 1, update snapshots, 28 objects, 8 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:13:54 - Current position: [    -10.017     0.18086     -2.0476], 1.773
00:13:57 - Question id b05e7b30-6a4d-4381-9d05-a42ed0c90e30 finished after arriving at target!
00:13:57 - Question id b05e7b30-6a4d-4381-9d05-a42ed0c90e30 finish successfully, 1.773304423174046 length
00:13:57 - 25/41: Success rate: 25/25
00:13:57 - Mean path length for success exploration: 1.1334997236983244
00:13:57 - Filtered snapshots/Total snapshots/Total frames: 3/8/10
00:13:57 - Scene graph of question b05e7b30-6a4d-4381-9d05-a42ed0c90e30:
00:13:57 - Question: is the table in the living room completely clean?
00:13:57 - Answer: no
00:13:57 - Prediction: The table in the living room is not completely clean; there is a book on it.
00:13:57 - 1-view_1.png:
00:13:57 - 	1: couch 9
00:13:57 - 	56: vent 1
00:13:57 - 	57: paper bag 1
00:13:57 - 0-view_0.png:
00:13:57 - 	2: coffee table 4
00:13:57 - 	3: book 5
00:13:57 - 	4: mat 1
00:13:57 - 0-view_6.png:
00:13:57 - 	8: fan 2
00:13:57 - 0-view_2.png:
00:13:57 - 	10: microwave 1
00:13:57 - 	11: stool 1
00:13:57 - 	12: trash bin 1
00:13:57 - 	13: counter 1
00:13:57 - 0-view_4.png:
00:13:57 - 	14: sink 4
00:13:57 - 	15: refrigerator 3
00:13:57 - 	27: tissue box 1
00:13:57 - 	29: picture 2
00:13:57 - 	32: cabinet 1
00:13:57 - 0-view_3.png:
00:13:57 - 	16: stool 3
00:13:57 - 	17: stool 2
00:13:57 - 	18: stool 2
00:13:57 - 	19: microwave 2
00:13:57 - 	20: picture 2
00:13:57 - 	21: shelf 2
00:13:57 - 	23: stove 2
00:13:57 - 1-view_0.png:
00:13:57 - 	25: paper bag 2
00:13:57 - 	37: shelf 2
00:13:57 - 	38: picture 2
00:13:57 - 1-view_2.png:
00:13:57 - 	45: picture 2
00:13:57 - 	60: fan 1
00:13:57 - 
========
Index: 25 Scene: 00880-Nfvxx8J5NCo
00:14:00 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:14:00 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:14:00 - 

Question id b93ea8d4-4b9a-46a3-b9b4-3d79c5ce074e initialization successful!
00:14:00 - 
== step: 0
00:14:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:14:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:14:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:14:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:14:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:14:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:14:11 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:14:13 - Step 0, update snapshots, 24 objects, 6 snapshots
00:14:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:14:16 - Prefiltering selected classes: ['cabinet', 'shelf', 'counter', 'sink', 'tissue box', 'trash bin']
00:14:16 - Prefiltering snapshot: 6 -> 4
00:14:19 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:14:19 - Response: [snapshot 3]
Reason: [The paper roll is not visible.]
00:14:19 - Prediction: snapshot, 3
00:14:19 - The index of target snapshot 4
00:14:19 - Pred_target_class: microwave stool trash bin counter
00:14:19 - Next choice Snapshot of 0-view_2.png
RuntimeWarning: invalid value encountered in divide
00:14:19 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 16 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:14:19 - Current position: [    -9.5166     0.18086    -0.34755], 0.000
00:14:22 - Question id b93ea8d4-4b9a-46a3-b9b4-3d79c5ce074e finished after arriving at target!
00:14:22 - Question id b93ea8d4-4b9a-46a3-b9b4-3d79c5ce074e finish successfully, 0.0 length
00:14:22 - 26/41: Success rate: 26/26
00:14:22 - Mean path length for success exploration: 1.0899035804791581
00:14:22 - Filtered snapshots/Total snapshots/Total frames: 4/6/7
00:14:22 - Scene graph of question b93ea8d4-4b9a-46a3-b9b4-3d79c5ce074e:
00:14:22 - Question: where is the paper roll?
00:14:22 - Answer: In the kitchen counter right next to the gas stove
00:14:22 - Prediction: The paper roll is not visible.
00:14:22 - 0-view_0.png:
00:14:22 - 	1: couch 4
00:14:22 - 	2: coffee table 2
00:14:22 - 	3: book 2
00:14:22 - 	4: mat 1
00:14:22 - 0-view_6.png:
00:14:22 - 	8: fan 2
00:14:22 - 0-view_2.png:
00:14:22 - 	10: microwave 1
00:14:22 - 	11: stool 1
00:14:22 - 	12: trash bin 1
00:14:22 - 	13: counter 1
00:14:22 - 0-view_4.png:
00:14:22 - 	14: sink 4
00:14:22 - 	15: refrigerator 3
00:14:22 - 	25: paper bag 1
00:14:22 - 	27: tissue box 1
00:14:22 - 	29: picture 2
00:14:22 - 	32: cabinet 1
00:14:22 - 0-view_3.png:
00:14:22 - 	16: stool 3
00:14:22 - 	17: stool 2
00:14:22 - 	18: stool 2
00:14:22 - 	19: microwave 2
00:14:22 - 	20: picture 2
00:14:22 - 	21: shelf 2
00:14:22 - 	23: stove 2
00:14:22 - 0-view_5.png:
00:14:22 - 	37: shelf 1
00:14:22 - 	38: picture 1
00:14:22 - 
========
Index: 26 Scene: 00876-mv2HUxq3B53
00:14:27 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:14:27 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:14:28 - 

Question id ba5f1c9b-9a41-4a84-829b-f9b8ccd19b69 initialization successful!
00:14:28 - 
== step: 0
00:14:30 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:14:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:14:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:14:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:14:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:14:37 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:14:38 - Step 0, update snapshots, 15 objects, 4 snapshots
00:14:53 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:14:53 - Prefiltering selected classes: ['cabinet']
00:14:53 - Prefiltering snapshot: 4 -> 1
00:14:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:14:55 - Response: [snapshot 0]
Reason: [You might want to check inside the cabinet for laundry detergent.]
00:14:55 - Prediction: snapshot, 0
00:14:55 - The index of target snapshot 0
00:14:55 - Pred_target_class: cabinet picture curtain picture tv
00:14:55 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:14:55 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:14:58 - 
== step: 1
00:14:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:15:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:15:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:15:02 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:15:03 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:15:05 - Question id ba5f1c9b-9a41-4a84-829b-f9b8ccd19b69 finished after arriving at target!
00:15:05 - Question id ba5f1c9b-9a41-4a84-829b-f9b8ccd19b69 finish successfully, 1.5295630140987002 length
00:15:05 - 27/41: Success rate: 27/27
00:15:05 - Mean path length for success exploration: 1.1061872632058078
00:15:05 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:15:05 - Scene graph of question ba5f1c9b-9a41-4a84-829b-f9b8ccd19b69:
00:15:05 - Question: Where do I reach for laundry detergent?
00:15:05 - Answer: For the shelf above the washing machine.
00:15:05 - Prediction: You might want to check inside the cabinet for laundry detergent.
00:15:05 - 0-view_1.png:
00:15:05 - 	1: telephone 1
00:15:05 - 	4: pillow 1
00:15:05 - 0-view_6.png:
00:15:05 - 	2: nightstand 4
00:15:05 - 	3: lamp 3
00:15:05 - 	27: picture 1
00:15:05 - 0-view_3.png:
00:15:05 - 	7: bed 6
00:15:05 - 	8: pillow 3
00:15:05 - 	12: pillow 1
00:15:05 - 	13: pillow 1
00:15:05 - 	14: blanket 1
00:15:05 - 0-view_5.png:
00:15:05 - 	11: cabinet 5
00:15:05 - 	16: picture 3
00:15:05 - 	18: curtain 3
00:15:05 - 	21: picture 1
00:15:05 - 	23: tv 1
00:15:05 - 
========
Index: 27 Scene: 00880-Nfvxx8J5NCo
00:15:09 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:15:09 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:15:09 - 

Question id bd5e9e4e-c6be-40e9-a923-fcc6aa321947 initialization successful!
00:15:09 - 
== step: 0
00:15:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:15:11 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:15:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:15:15 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:15:16 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:15:18 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:15:20 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:15:21 - Step 0, update snapshots, 24 objects, 6 snapshots
00:15:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:15:24 - Prefiltering selected classes: []
00:15:24 - Prefiltering snapshot: 6 -> 0
00:15:24 - Input prompt:
00:15:24 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: is the television on or off?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:15:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:15:29 - Response: [frontier 2]
Reason: [To check the television's status, as it is visible in this direction.]
00:15:29 - Prediction: frontier, 2
00:15:29 - Next choice: Frontier at [76 74]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:15:29 - Current position: [    -8.6166     0.18086    -0.74755], 0.985
00:15:31 - 
== step: 1
00:15:32 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:15:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:15:35 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:15:35 - Step 1, update snapshots, 27 objects, 8 snapshots
00:15:38 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:15:38 - Prefiltering selected classes: ['couch']
00:15:38 - Prefiltering snapshot: 8 -> 1
00:15:40 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:15:40 - Response: [snapshot 0]
Reason: [The television is not visible.]
00:15:40 - Prediction: snapshot, 0
00:15:40 - The index of target snapshot 0
00:15:40 - Pred_target_class: couch coffee table book mat
00:15:40 - Next choice Snapshot of 0-view_0.png
RuntimeWarning: invalid value encountered in divide
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:15:40 - Current position: [    -9.4166     0.18086     -1.4476], 2.048
00:15:43 - 
== step: 2
00:15:44 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:15:45 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:15:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:15:48 - Step 2, update snapshots, 29 objects, 10 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:15:49 - Current position: [    -10.017     0.18086     -2.0476], 2.896
00:15:51 - Question id bd5e9e4e-c6be-40e9-a923-fcc6aa321947 finished after arriving at target!
00:15:51 - Question id bd5e9e4e-c6be-40e9-a923-fcc6aa321947 finish successfully, 2.896428498876933 length
00:15:51 - 28/41: Success rate: 28/28
00:15:51 - Mean path length for success exploration: 1.1701244501940624
00:15:51 - Filtered snapshots/Total snapshots/Total frames: 1/10/13
00:15:51 - Scene graph of question bd5e9e4e-c6be-40e9-a923-fcc6aa321947:
00:15:51 - Question: is the television on or off?
00:15:51 - Answer: off
00:15:51 - Prediction: The television is not visible.
00:15:51 - 0-view_0.png:
00:15:51 - 	1: couch 11
00:15:51 - 	2: coffee table 6
00:15:51 - 	3: book 6
00:15:51 - 	4: mat 1
00:15:51 - 0-view_6.png:
00:15:51 - 	8: fan 2
00:15:51 - 0-view_2.png:
00:15:51 - 	10: microwave 1
00:15:51 - 	11: stool 1
00:15:51 - 	12: trash bin 1
00:15:51 - 	13: counter 1
00:15:51 - 0-view_4.png:
00:15:51 - 	14: sink 4
00:15:51 - 	15: refrigerator 4
00:15:51 - 	25: paper bag 3
00:15:51 - 	27: tissue box 1
00:15:51 - 	32: cabinet 1
00:15:51 - 0-view_3.png:
00:15:51 - 	16: stool 3
00:15:51 - 	17: stool 2
00:15:51 - 	18: stool 2
00:15:51 - 	19: microwave 2
00:15:51 - 	20: picture 3
00:15:51 - 	21: shelf 2
00:15:51 - 	23: stove 2
00:15:51 - 1-view_2.png:
00:15:51 - 	29: picture 3
00:15:51 - 	46: picture 2
00:15:51 - 	55: picture 2
00:15:51 - 0-view_5.png:
00:15:51 - 	37: shelf 3
00:15:51 - 	38: picture 1
00:15:51 - 1-view_0.png:
00:15:51 - 	47: stool 1
00:15:51 - 2-view_1.png:
00:15:51 - 	69: blinds 1
00:15:51 - 2-view_2.png:
00:15:51 - 	72: picture 1
00:15:51 - 
========
Index: 28 Scene: 00880-Nfvxx8J5NCo
00:15:54 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:15:54 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:15:55 - 

Question id c1b2ccf5-b56d-4ced-9cec-eaf62fedc675 initialization successful!
00:15:55 - 
== step: 0
00:15:55 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:15:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:15:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:16:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:16:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:16:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:16:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:16:06 - Step 0, update snapshots, 24 objects, 6 snapshots
00:16:10 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:10 - Prefiltering selected classes: []
00:16:10 - Prefiltering snapshot: 6 -> 0
00:16:10 - Input prompt:
00:16:10 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:16:14 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:14 - Response: [frontier 0]
Reason: [The wall clock might be visible in the dining area.]
00:16:14 - Prediction: frontier, 0
00:16:14 - Next choice: Frontier at [44 64]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:16:14 - Current position: [    -10.517     0.18086    -0.14755], 1.020
00:16:16 - 
== step: 1
00:16:17 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:16:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:16:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:16:22 - Step 1, update snapshots, 30 objects, 8 snapshots
00:16:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:24 - Prefiltering selected classes: []
00:16:24 - Prefiltering snapshot: 8 -> 0
00:16:24 - Input prompt:
00:16:24 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:16:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:28 - Response: [frontier 2]
Reason: [The wall clock might be visible from this direction near the dining area.]
00:16:28 - Prediction: frontier, 2
00:16:28 - Next choice: Frontier at [36 58]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:16:28 - Current position: [    -11.417     0.18086     0.25245], 2.005
00:16:30 - 
== step: 2
00:16:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:16:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:16:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:16:35 - Step 2, update snapshots, 33 objects, 10 snapshots
00:16:39 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:39 - Prefiltering selected classes: []
00:16:39 - Prefiltering snapshot: 10 -> 0
00:16:39 - Input prompt:
00:16:39 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Frontier 3 [iVBORw0KGg...]
Frontier 4 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:16:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:43 - Response: [frontier 1]
Reason: [I see a hallway that might lead to a room with a wall clock.]
00:16:43 - Prediction: frontier, 1
00:16:43 - Next choice: Frontier at [76 74]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:16:43 - Current position: [    -10.517     0.18086    -0.14755], 2.990
00:16:46 - 
== step: 3
00:16:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:16:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:16:51 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:16:53 - Done! Execution time of denoise_objects function: 1.69 seconds
00:16:53 - Done! Execution time of merge_objects function: 0.20 seconds
00:16:54 - Step 3, update snapshots, 26 objects, 9 snapshots
00:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:16:57 - Prefiltering selected classes: []
00:16:57 - Prefiltering snapshot: 9 -> 0
00:16:57 - Input prompt:
00:16:57 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Frontier 3 [iVBORw0KGg...]
Frontier 4 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:17:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:02 - Response: [frontier 1]
Reason: [I see a wall with potential space for a clock, which might provide a view of the clock numbers.]
00:17:02 - Prediction: frontier, 1
00:17:02 - Next choice: Frontier at [76 74]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:17:02 - Current position: [    -9.6166     0.18086    -0.44755], 3.938
00:17:05 - 
== step: 4
00:17:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:17:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:17:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:17:10 - Step 4, update snapshots, 31 objects, 10 snapshots
00:17:12 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:12 - Prefiltering selected classes: []
00:17:12 - Prefiltering snapshot: 10 -> 0
00:17:12 - Input prompt:
00:17:12 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Frontier 3 [iVBORw0KGg...]
Frontier 4 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:17:19 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:19 - Response: [frontier 3]
Reason: [The wall clock might be in the dining area or on a nearby wall. Exploring this area could help locate it.]
00:17:19 - Prediction: frontier, 3
00:17:19 - Next choice: Frontier at [41 45]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:17:19 - Current position: [    -10.417     0.18086     0.15245], 4.938
00:17:22 - 
== step: 5
00:17:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:17:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:17:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:17:27 - Step 5, update snapshots, 32 objects, 10 snapshots
00:17:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:29 - Prefiltering selected classes: []
00:17:29 - Prefiltering snapshot: 10 -> 0
00:17:29 - Input prompt:
00:17:29 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: what color are the numbers written on the wall clock?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Frontier 2 [iVBORw0KGg...]
Frontier 3 [iVBORw0KGg...]
Frontier 4 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:17:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:34 - Response: [frontier 1]
Reason: [The wall clock is visible in this direction near the dining area. Exploring further might reveal the color of the numbers.]
00:17:34 - Prediction: frontier, 1
00:17:34 - Next choice: Frontier at [28 67]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:17:34 - Current position: [    -11.417     0.18086    -0.04755], 5.958
00:17:37 - 
== step: 6
00:17:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:17:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:17:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:17:42 - Step 6, update snapshots, 34 objects, 10 snapshots
00:17:44 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:44 - Prefiltering selected classes: ['mirror']
00:17:44 - Prefiltering snapshot: 10 -> 1
00:17:46 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:17:46 - Response: [snapshot 0]
Reason: [I can't determine the color of the numbers on the wall clock.]
00:17:46 - Prediction: snapshot, 0
00:17:46 - The index of target snapshot 0
00:17:46 - Pred_target_class: shelf mirror
00:17:46 - Next choice Snapshot of 4-view_2.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:17:46 - Current position: [    -10.517     0.18086    -0.54755], 6.988
00:17:50 - 
== step: 7
00:17:51 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:17:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:17:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:17:57 - Done! Execution time of denoise_objects function: 2.32 seconds
00:17:57 - Done! Execution time of merge_objects function: 0.27 seconds
00:17:57 - Step 7, update snapshots, 30 objects, 9 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:17:58 - Current position: [    -9.6166     0.18086     -1.0476], 8.017
00:18:01 - 
== step: 8
00:18:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:18:03 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:18:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:18:06 - Step 8, update snapshots, 33 objects, 10 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:18:07 - Current position: [    -8.7166     0.18086     -1.5476], 9.047
00:18:10 - 
== step: 9
00:18:10 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:18:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:18:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:18:14 - Step 9, update snapshots, 34 objects, 12 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:18:15 - Current position: [    -8.0166     0.18086     -2.0476], 9.907
00:18:18 - Question id c1b2ccf5-b56d-4ced-9cec-eaf62fedc675 finished after arriving at target!
00:18:18 - Question id c1b2ccf5-b56d-4ced-9cec-eaf62fedc675 finish successfully, 9.906984232847213 length
00:18:18 - 29/41: Success rate: 29/29
00:18:18 - Mean path length for success exploration: 1.471395477182102
00:18:18 - Filtered snapshots/Total snapshots/Total frames: 1/12/34
00:18:18 - Scene graph of question c1b2ccf5-b56d-4ced-9cec-eaf62fedc675:
00:18:18 - Question: what color are the numbers written on the wall clock?
00:18:18 - Answer: white
00:18:18 - Prediction: I can't determine the color of the numbers on the wall clock.
00:18:18 - 0-view_0.png:
00:18:18 - 	1: couch 28
00:18:18 - 	2: coffee table 12
00:18:18 - 	3: book 10
00:18:18 - 	4: mat 1
00:18:18 - 3-view_0.png:
00:18:18 - 	8: fan 3
00:18:18 - 	11: stool 4
00:18:18 - 0-view_2.png:
00:18:18 - 	12: trash bin 1
00:18:18 - 4-view_0.png:
00:18:18 - 	13: counter 5
00:18:18 - 	14: sink 8
00:18:18 - 	18: stool 5
00:18:18 - 0-view_3.png:
00:18:18 - 	15: refrigerator 7
00:18:18 - 	16: stool 7
00:18:18 - 	17: stool 7
00:18:18 - 	19: microwave 6
00:18:18 - 	20: picture 5
00:18:18 - 	21: shelf 2
00:18:18 - 	23: towel 6
00:18:18 - 4-view_1.png:
00:18:18 - 	29: picture 5
00:18:18 - 6-view_2.png:
00:18:18 - 	47: mat 6
00:18:18 - 	48: chair 9
00:18:18 - 	50: bench 9
00:18:18 - 	57: dining table 6
00:18:18 - 	141: picture 2
00:18:18 - 5-view_1.png:
00:18:18 - 	53: picture 4
00:18:18 - 	75: shelf 2
00:18:18 - 	130: bench 1
00:18:18 - 1-view_1.png:
00:18:18 - 	55: bench 2
00:18:18 - 8-view_1.png:
00:18:18 - 	88: fan 4
00:18:18 - 9-view_1.png:
00:18:18 - 	108: paper bag 5
00:18:18 - 	110: shelf 9
00:18:18 - 	172: picture 3
00:18:18 - 	175: picture 3
00:18:18 - 	177: tv 4
00:18:18 - 9-view_0.png:
00:18:18 - 	184: picture 2
00:18:18 - 
========
Index: 29 Scene: 00824-Dd4bFSTQ8gi
00:18:21 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:18:21 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:18:22 - 

Question id cbffc0cd-04aa-4686-97bf-887c0dc840bd initialization successful!
00:18:22 - 
== step: 0
00:18:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:18:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:18:25 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:18:27 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:18:28 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:18:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:18:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:18:32 - Step 0, update snapshots, 12 objects, 4 snapshots
00:18:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:18:34 - Prefiltering selected classes: ['picture']
00:18:34 - Prefiltering snapshot: 4 -> 2
00:18:37 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:18:37 - Response: [snapshot 0]
Reason: [The painting above the couch features an abstract design with a mix of colors and shapes.]
00:18:37 - Prediction: snapshot, 0
00:18:37 - The index of target snapshot 1
00:18:37 - Pred_target_class: potted plant picture folded chair
00:18:37 - Next choice Snapshot of 0-view_0.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:18:37 - Current position: [     6.3147    0.068824      0.7036], 1.000
00:18:39 - 
== step: 1
00:18:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.03 seconds
00:18:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:18:42 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:18:43 - Step 1, update snapshots, 13 objects, 5 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:18:44 - Current position: [     6.1147    0.068824      0.5036], 1.283
00:18:46 - Question id cbffc0cd-04aa-4686-97bf-887c0dc840bd finished after arriving at target!
00:18:46 - Question id cbffc0cd-04aa-4686-97bf-887c0dc840bd finish successfully, 1.2828427124746191 length
00:18:46 - 30/41: Success rate: 30/30
00:18:46 - Mean path length for success exploration: 1.4651103850251859
00:18:46 - Filtered snapshots/Total snapshots/Total frames: 2/5/8
00:18:46 - Scene graph of question cbffc0cd-04aa-4686-97bf-887c0dc840bd:
00:18:46 - Question: What is shown on the painting above the couch?
00:18:46 - Answer: Horses
00:18:46 - Prediction: The painting above the couch features an abstract design with a mix of colors and shapes.
00:18:46 - 0-view_0.png:
00:18:46 - 	1: potted plant 3
00:18:46 - 	2: picture 3
00:18:46 - 	4: folded chair 1
00:18:46 - 0-view_5.png:
00:18:46 - 	3: bed 4
00:18:46 - 	7: plate 3
00:18:46 - 	9: folded chair 2
00:18:46 - 	11: plate 2
00:18:46 - 	12: table 2
00:18:46 - 	21: chair 1
00:18:46 - 0-view_3.png:
00:18:46 - 	8: sofa chair 1
00:18:46 - 	10: pillow 1
00:18:46 - 0-view_4.png:
00:18:46 - 	14: picture 1
00:18:46 - 1-view_1.png:
00:18:46 - 	23: coffee table 1
00:18:46 - 
========
Index: 30 Scene: 00876-mv2HUxq3B53
00:18:52 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:18:52 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:18:52 - 

Question id d3742804-8363-4346-a622-5bcaeffb25e9 initialization successful!
00:18:52 - 
== step: 0
00:18:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:18:56 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:18:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:18:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:19:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:19:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:19:03 - Step 0, update snapshots, 15 objects, 4 snapshots
00:19:05 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:05 - Prefiltering selected classes: ['cabinet', 'nightstand', 'lamp', 'picture', 'tv']
00:19:05 - Prefiltering snapshot: 4 -> 2
00:19:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:08 - Response: [snapshot 1]
Reason: [The round mirror is above the bed.]
00:19:08 - Prediction: snapshot, 1
00:19:08 - The index of target snapshot 2
00:19:08 - Pred_target_class: picture nightstand lamp
00:19:08 - Next choice Snapshot of 0-view_6.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:19:08 - Current position: [    -7.4732    0.050354      7.9939], 0.583
00:19:10 - Question id d3742804-8363-4346-a622-5bcaeffb25e9 finished after arriving at target!
00:19:10 - Question id d3742804-8363-4346-a622-5bcaeffb25e9 finish successfully, 0.5830951894845301 length
00:19:10 - 31/41: Success rate: 31/31
00:19:10 - Mean path length for success exploration: 1.4366582819432294
00:19:10 - Filtered snapshots/Total snapshots/Total frames: 2/4/6
00:19:10 - Scene graph of question d3742804-8363-4346-a622-5bcaeffb25e9:
00:19:10 - Question: Where is the round mirror?
00:19:10 - Answer: On the wall above the head of the bed in the first bedroom.
00:19:10 - Prediction: The round mirror is above the bed.
00:19:10 - 0-view_1.png:
00:19:10 - 	1: telephone 1
00:19:10 - 	4: pillow 1
00:19:10 - 0-view_6.png:
00:19:10 - 	2: nightstand 3
00:19:10 - 	3: lamp 3
00:19:10 - 	27: picture 1
00:19:10 - 0-view_3.png:
00:19:10 - 	7: bed 4
00:19:10 - 	8: pillow 2
00:19:10 - 	12: pillow 1
00:19:10 - 	13: pillow 1
00:19:10 - 	14: blanket 1
00:19:10 - 0-view_5.png:
00:19:10 - 	11: cabinet 3
00:19:10 - 	16: picture 2
00:19:10 - 	18: curtain 2
00:19:10 - 	21: picture 1
00:19:10 - 	23: tv 1
00:19:10 - 
========
Index: 31 Scene: 00880-Nfvxx8J5NCo
00:19:13 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:19:13 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:19:14 - 

Question id d4c10718-fd57-4db0-93c1-b54deb4b1b25 initialization successful!
00:19:14 - 
== step: 0
00:19:14 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:19:16 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:19:18 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.13 seconds
00:19:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:19:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:19:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:19:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:19:26 - Step 0, update snapshots, 24 objects, 6 snapshots
00:19:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:28 - Prefiltering selected classes: ['sink', 'tissue box', 'counter', 'paper bag', 'trash bin']
00:19:28 - Prefiltering snapshot: 6 -> 2
00:19:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:32 - Response: [snapshot 1]
Reason: [You can clean your hands by using the sink.]
00:19:32 - Prediction: snapshot, 1
00:19:32 - The index of target snapshot 4
00:19:32 - Pred_target_class: microwave stool trash bin counter
00:19:32 - Next choice Snapshot of 0-view_2.png
RuntimeWarning: invalid value encountered in divide
00:19:32 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 16 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:19:32 - Current position: [    -9.5166     0.18086    -0.34755], 0.000
00:19:34 - Question id d4c10718-fd57-4db0-93c1-b54deb4b1b25 finished after arriving at target!
00:19:34 - Question id d4c10718-fd57-4db0-93c1-b54deb4b1b25 finish successfully, 0.0 length
00:19:34 - 32/41: Success rate: 32/32
00:19:34 - Mean path length for success exploration: 1.3917627106325032
00:19:34 - Filtered snapshots/Total snapshots/Total frames: 2/6/7
00:19:34 - Scene graph of question d4c10718-fd57-4db0-93c1-b54deb4b1b25:
00:19:34 - Question: how can I clean my hands?
00:19:34 - Answer: there is a sink in the kitchen
00:19:34 - Prediction: You can clean your hands by using the sink.
00:19:34 - 0-view_0.png:
00:19:34 - 	1: couch 4
00:19:34 - 	2: coffee table 2
00:19:34 - 	3: book 2
00:19:34 - 	4: mat 1
00:19:34 - 0-view_6.png:
00:19:34 - 	8: fan 2
00:19:34 - 0-view_2.png:
00:19:34 - 	10: microwave 1
00:19:34 - 	11: stool 1
00:19:34 - 	12: trash bin 1
00:19:34 - 	13: counter 1
00:19:34 - 0-view_4.png:
00:19:34 - 	14: sink 4
00:19:34 - 	15: refrigerator 3
00:19:34 - 	25: paper bag 1
00:19:34 - 	27: tissue box 1
00:19:34 - 	29: picture 2
00:19:34 - 	32: cabinet 1
00:19:34 - 0-view_3.png:
00:19:34 - 	16: stool 3
00:19:34 - 	17: stool 2
00:19:34 - 	18: stool 2
00:19:34 - 	19: microwave 2
00:19:34 - 	20: picture 2
00:19:34 - 	21: shelf 2
00:19:34 - 	23: stove 2
00:19:34 - 0-view_5.png:
00:19:34 - 	37: shelf 1
00:19:34 - 	38: picture 1
00:19:34 - 
========
Index: 32 Scene: 00880-Nfvxx8J5NCo
00:19:37 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:19:37 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:19:38 - 

Question id d8183087-f3dd-47c1-b985-733923edc4a0 initialization successful!
00:19:38 - 
== step: 0
00:19:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:19:40 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:19:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:19:43 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:19:45 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:19:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:19:48 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:19:50 - Step 0, update snapshots, 24 objects, 6 snapshots
00:19:52 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:52 - Prefiltering selected classes: ['fan']
00:19:52 - Prefiltering snapshot: 6 -> 1
00:19:54 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:19:54 - Response: [snapshot 0]
Reason: [The fan is off.]
00:19:54 - Prediction: snapshot, 0
00:19:54 - The index of target snapshot 5
00:19:54 - Pred_target_class: fan
00:19:54 - Next choice Snapshot of 0-view_6.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:19:55 - Current position: [    -10.317     0.18086     0.05245], 0.894
00:19:57 - Question id d8183087-f3dd-47c1-b985-733923edc4a0 finished after arriving at target!
00:19:57 - Question id d8183087-f3dd-47c1-b985-733923edc4a0 finish successfully, 0.894427190999916 length
00:19:57 - 33/41: Success rate: 33/33
00:19:57 - Mean path length for success exploration: 1.3766919373103035
00:19:57 - Filtered snapshots/Total snapshots/Total frames: 1/6/7
00:19:57 - Scene graph of question d8183087-f3dd-47c1-b985-733923edc4a0:
00:19:57 - Question: is the fan on or off?
00:19:57 - Answer: off
00:19:57 - Prediction: The fan is off.
00:19:57 - 0-view_0.png:
00:19:57 - 	1: couch 4
00:19:57 - 	2: coffee table 2
00:19:57 - 	3: book 2
00:19:57 - 	4: mat 1
00:19:57 - 0-view_6.png:
00:19:57 - 	8: fan 2
00:19:57 - 0-view_2.png:
00:19:57 - 	10: microwave 1
00:19:57 - 	11: stool 1
00:19:57 - 	12: trash bin 1
00:19:57 - 	13: counter 1
00:19:57 - 0-view_4.png:
00:19:57 - 	14: sink 4
00:19:57 - 	15: refrigerator 3
00:19:57 - 	25: paper bag 1
00:19:57 - 	27: tissue box 1
00:19:57 - 	29: picture 2
00:19:57 - 	32: cabinet 1
00:19:57 - 0-view_3.png:
00:19:57 - 	16: stool 3
00:19:57 - 	17: stool 2
00:19:57 - 	18: stool 2
00:19:57 - 	19: microwave 2
00:19:57 - 	20: picture 2
00:19:57 - 	21: shelf 2
00:19:57 - 	23: stove 2
00:19:57 - 0-view_5.png:
00:19:57 - 	37: shelf 1
00:19:57 - 	38: picture 1
00:19:57 - 
========
Index: 33 Scene: 00880-Nfvxx8J5NCo
00:20:00 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:20:00 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:20:00 - 

Question id de038605-c441-4a30-968b-7815bad3a3c9 initialization successful!
00:20:00 - 
== step: 0
00:20:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:02 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:20:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:20:06 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:20:08 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:20:09 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:20:11 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:20:12 - Step 0, update snapshots, 24 objects, 6 snapshots
00:20:15 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:20:15 - Prefiltering selected classes: ['stool']
00:20:15 - Prefiltering snapshot: 6 -> 2
00:20:18 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:20:18 - Response: [snapshot 0]
Reason: [The chairs are black.]
00:20:18 - Prediction: snapshot, 0
00:20:18 - The index of target snapshot 2
00:20:18 - Pred_target_class: microwave shelf stove picture stool stool stool
00:20:18 - Next choice Snapshot of 0-view_3.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:20:19 - Current position: [    -9.0166     0.18086     0.35245], 0.860
00:20:21 - Question id de038605-c441-4a30-968b-7815bad3a3c9 finished after arriving at target!
00:20:21 - Question id de038605-c441-4a30-968b-7815bad3a3c9 finish successfully, 0.8602325267042628 length
00:20:21 - 34/41: Success rate: 34/34
00:20:21 - Mean path length for success exploration: 1.3615019546454201
00:20:21 - Filtered snapshots/Total snapshots/Total frames: 2/6/7
00:20:21 - Scene graph of question de038605-c441-4a30-968b-7815bad3a3c9:
00:20:21 - Question: what color are the chairs?
00:20:21 - Answer: brown
00:20:21 - Prediction: The chairs are black.
00:20:21 - 0-view_0.png:
00:20:21 - 	1: couch 4
00:20:21 - 	2: coffee table 2
00:20:21 - 	3: book 2
00:20:21 - 	4: mat 1
00:20:21 - 0-view_6.png:
00:20:21 - 	8: fan 2
00:20:21 - 0-view_2.png:
00:20:21 - 	10: microwave 1
00:20:21 - 	11: stool 1
00:20:21 - 	12: trash bin 1
00:20:21 - 	13: counter 1
00:20:21 - 0-view_4.png:
00:20:21 - 	14: sink 4
00:20:21 - 	15: refrigerator 3
00:20:21 - 	25: paper bag 1
00:20:21 - 	27: tissue box 1
00:20:21 - 	29: picture 2
00:20:21 - 	32: cabinet 1
00:20:21 - 0-view_3.png:
00:20:21 - 	16: stool 3
00:20:21 - 	17: stool 2
00:20:21 - 	18: stool 2
00:20:21 - 	19: microwave 2
00:20:21 - 	20: picture 2
00:20:21 - 	21: shelf 2
00:20:21 - 	23: stove 2
00:20:21 - 0-view_5.png:
00:20:21 - 	37: shelf 1
00:20:21 - 	38: picture 1
00:20:21 - 
========
Index: 34 Scene: 00876-mv2HUxq3B53
00:20:26 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:20:26 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:20:27 - 

Question id dfdc3b36-d98f-42a7-b2ea-dceb4af1794a initialization successful!
00:20:27 - 
== step: 0
00:20:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:20:30 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:32 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:20:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:20:37 - Step 0, update snapshots, 15 objects, 4 snapshots
00:20:39 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:20:39 - Prefiltering selected classes: ['bed', 'cabinet', 'nightstand']
00:20:39 - Prefiltering snapshot: 4 -> 3
00:20:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:20:43 - Response: [snapshot 1]
Reason: [The ceiling fan is positioned above the bed.]
00:20:43 - Prediction: snapshot, 1
00:20:43 - The index of target snapshot 1
00:20:43 - Pred_target_class: pillow blanket bed pillow pillow
00:20:43 - Next choice Snapshot of 0-view_3.png
RuntimeWarning: invalid value encountered in divide
00:20:43 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 7 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:20:43 - Current position: [    -7.9732    0.050354      8.2939], 0.000
00:20:46 - Question id dfdc3b36-d98f-42a7-b2ea-dceb4af1794a finished after arriving at target!
00:20:46 - Question id dfdc3b36-d98f-42a7-b2ea-dceb4af1794a finish successfully, 0.0 length
00:20:46 - 35/41: Success rate: 35/35
00:20:46 - Mean path length for success exploration: 1.322601898798408
00:20:46 - Filtered snapshots/Total snapshots/Total frames: 3/4/6
00:20:46 - Scene graph of question dfdc3b36-d98f-42a7-b2ea-dceb4af1794a:
00:20:46 - Question: Where is the ceiling fan?
00:20:46 - Answer: Above the bed in the second bedroom
00:20:46 - Prediction: The ceiling fan is positioned above the bed.
00:20:46 - 0-view_1.png:
00:20:46 - 	1: telephone 1
00:20:46 - 	4: pillow 1
00:20:46 - 0-view_6.png:
00:20:46 - 	2: nightstand 3
00:20:46 - 	3: lamp 3
00:20:46 - 	27: picture 1
00:20:46 - 0-view_3.png:
00:20:46 - 	7: bed 4
00:20:46 - 	8: pillow 2
00:20:46 - 	12: pillow 1
00:20:46 - 	13: pillow 1
00:20:46 - 	14: blanket 1
00:20:46 - 0-view_5.png:
00:20:46 - 	11: cabinet 3
00:20:46 - 	16: picture 2
00:20:46 - 	18: curtain 2
00:20:46 - 	21: picture 1
00:20:46 - 	23: tv 1
00:20:46 - 
========
Index: 35 Scene: 00876-mv2HUxq3B53
00:20:51 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:20:51 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:20:52 - 

Question id e0d20472-8fa6-4e8d-880d-22d4eed3fbb8 initialization successful!
00:20:52 - 
== step: 0
00:20:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:20:55 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:20:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:20:59 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:21:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:21:02 - Step 0, update snapshots, 15 objects, 4 snapshots
00:21:05 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:21:05 - Prefiltering selected classes: ['tv']
00:21:05 - Prefiltering snapshot: 4 -> 1
00:21:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:21:07 - Response: [snapshot 0]
Reason: [The television is turned on.]
00:21:07 - Prediction: snapshot, 0
00:21:07 - The index of target snapshot 0
00:21:07 - Pred_target_class: cabinet picture curtain picture tv
00:21:07 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:21:08 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:21:10 - 
== step: 1
00:21:11 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:21:12 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:21:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:21:14 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:21:15 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:21:17 - Question id e0d20472-8fa6-4e8d-880d-22d4eed3fbb8 finished after arriving at target!
00:21:17 - Question id e0d20472-8fa6-4e8d-880d-22d4eed3fbb8 finish successfully, 1.5295630140987002 length
00:21:17 - 36/41: Success rate: 36/36
00:21:17 - Mean path length for success exploration: 1.3283508186678605
00:21:17 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:21:17 - Scene graph of question e0d20472-8fa6-4e8d-880d-22d4eed3fbb8:
00:21:17 - Question: Is the television turned on or off?
00:21:17 - Answer: On
00:21:17 - Prediction: The television is turned on.
00:21:17 - 0-view_1.png:
00:21:17 - 	1: telephone 1
00:21:17 - 	4: pillow 1
00:21:17 - 0-view_6.png:
00:21:17 - 	2: nightstand 4
00:21:17 - 	3: lamp 3
00:21:17 - 	27: picture 1
00:21:17 - 0-view_3.png:
00:21:17 - 	7: bed 6
00:21:17 - 	8: pillow 3
00:21:17 - 	12: pillow 1
00:21:17 - 	13: pillow 1
00:21:17 - 	14: blanket 1
00:21:17 - 0-view_5.png:
00:21:17 - 	11: cabinet 5
00:21:17 - 	16: picture 3
00:21:17 - 	18: curtain 3
00:21:17 - 	21: picture 1
00:21:17 - 	23: tv 1
00:21:17 - 
========
Index: 36 Scene: 00848-ziup5kvtCCR
00:21:20 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:21:20 - Load scene 00848-ziup5kvtCCR successfully with semantic texture
00:21:21 - 

Question id e6fb0c2e-5f92-4835-ba38-6af958b7a1d3 initialization successful!
00:21:21 - 
== step: 0
00:21:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.16 seconds
00:21:24 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:21:26 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:21:27 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:21:29 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:21:30 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:21:31 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:21:32 - Step 0, update snapshots, 25 objects, 7 snapshots
00:21:36 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:21:36 - Prefiltering selected classes: ['sofa chair', 'couch', 'cabinet', 'mirror', 'curtain']
00:21:36 - Prefiltering snapshot: 7 -> 6
00:21:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:21:43 - Response: [snapshot 0]
Reason: [There is a window with curtains behind the armchair in the living room.]
00:21:43 - Prediction: snapshot, 0
00:21:43 - The index of target snapshot 0
00:21:43 - Pred_target_class: lamp coffee table potted plant pillow pillow pillow pillow couch
00:21:43 - Next choice Snapshot of 0-view_0.png
00:21:43 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 1 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:21:43 - Current position: [    0.21692    0.021223      7.1057], 0.000
00:21:46 - Question id e6fb0c2e-5f92-4835-ba38-6af958b7a1d3 finished after arriving at target!
00:21:46 - Question id e6fb0c2e-5f92-4835-ba38-6af958b7a1d3 finish successfully, 0.0 length
00:21:46 - 37/41: Success rate: 37/37
00:21:46 - Mean path length for success exploration: 1.2924494451903508
00:21:46 - Filtered snapshots/Total snapshots/Total frames: 6/7/7
00:21:46 - Scene graph of question e6fb0c2e-5f92-4835-ba38-6af958b7a1d3:
00:21:46 - Question: What is behind the armchair in the living room?
00:21:46 - Answer: A dog bed
00:21:46 - Prediction: There is a window with curtains behind the armchair in the living room.
00:21:46 - 0-view_0.png:
00:21:46 - 	1: lamp 1
00:21:46 - 	2: pillow 3
00:21:46 - 	4: couch 2
00:21:46 - 	5: coffee table 1
00:21:46 - 	6: potted plant 1
00:21:46 - 	7: pillow 2
00:21:46 - 	8: pillow 2
00:21:46 - 	9: pillow 1
00:21:46 - 0-view_2.png:
00:21:46 - 	3: pillow 3
00:21:46 - 	18: couch 2
00:21:46 - 0-view_1.png:
00:21:46 - 	10: coffee table 3
00:21:46 - 	11: sofa chair 3
00:21:46 - 	14: pillow 1
00:21:46 - 0-view_6.png:
00:21:46 - 	21: cabinet 3
00:21:46 - 	25: tv 2
00:21:46 - 	26: potted plant 3
00:21:46 - 0-view_3.png:
00:21:46 - 	24: mirror 1
00:21:46 - 0-view_4.png:
00:21:46 - 	28: clock 2
00:21:46 - 	29: bottle 2
00:21:46 - 0-view_5.png:
00:21:46 - 	30: mirror 2
00:21:46 - 	32: clock 2
00:21:46 - 	35: lamp 2
00:21:46 - 	39: curtain 1
00:21:46 - 	40: candle 1
00:21:46 - 	41: potted plant 1
00:21:46 - 
========
Index: 37 Scene: 00876-mv2HUxq3B53
00:21:51 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:21:51 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:21:52 - 

Question id f17869a2-2a4d-4ce4-b262-cb69618e3394 initialization successful!
00:21:52 - 
== step: 0
00:21:54 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:21:55 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:21:57 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:21:58 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:22:00 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:22:01 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:22:02 - Step 0, update snapshots, 15 objects, 4 snapshots
00:22:05 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:05 - Prefiltering selected classes: []
00:22:05 - Prefiltering snapshot: 4 -> 0
00:22:05 - Input prompt:
00:22:05 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: Is the toilet seat open or closed?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:22:09 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:09 - Response: [frontier 1]
Reason: [I see a hallway that may lead to a bathroom.]
00:22:09 - Prediction: frontier, 1
00:22:09 - Next choice: Frontier at [ 44 102]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:22:09 - Current position: [    -6.9732    0.050354      8.3939], 1.005
00:22:11 - 
== step: 1
00:22:14 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.01 seconds
00:22:14 - Step 1, update snapshots, 15 objects, 4 snapshots
00:22:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:16 - Prefiltering selected classes: []
00:22:16 - Prefiltering snapshot: 4 -> 0
00:22:16 - Input prompt:
00:22:16 - Task: You are an agent in an indoor scene tasked with answering questions by observing the surroundings and exploring the environment. To answer the question, you are required to choose either a snapshot as the answer or a Frontier to further explore.
Definitions:
snapshot: A focused observation of several objects. Choosing a snapshot means that this snapshot image contains enough information for you to answer the question. If you choose a snapshot, you need to directly give an answer to the question. If you don't have enough information to give an answer, then don't choose a snapshot.
Frontier: An observation of an unexplored region that could potentially lead to new information for answering the question. Selecting a frontier means that you will further explore that direction. If you choose a Frontier, you need to explain why you would like to choose that direction to explore.
Question: Is the toilet seat open or closed?
Select the Frontier/snapshot that would help find the answer of the question.
The following is the egocentric view of the agent in forward direction: [iVBORw0KGg...]
The followings are all the snapshots that you can choose (followed with contained object classes)
Please note that the contained classes may not be accurate (wrong classes/missing classes) due to the limitation of the object detection model. So you still need to utilize the images to make decisions.
No snapshot is available
The followings are all the Frontiers that you can explore: 
Frontier 0 [iVBORw0KGg...]
Frontier 1 [iVBORw0KGg...]
Please provide your answer in the following format: 'snapshot i
[Answer]' or 'Frontier i
[Reason]', where i is the index of the snapshot or frontier you choose. For example, if you choose the first snapshot, you can return 'snapshot 0
The fruit bowl is on the kitchen counter.'. If you choose the second frontier, you can return 'Frontier 1
I see a door that may lead to the living room.'.
Note that if you choose a snapshot to answer the question, (1) you should give a direct answer that can be understood by others. Don't mention words like 'snapshot', 'on the left of the image', etc; (2) you can also utilize other snapshots, frontiers and egocentric views to gather more information, but you should always choose one most relevant snapshot to answer the question.

00:22:18 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:18 - Response: [frontier 1]
Reason: [The door on the right might lead to a bathroom where I can check the toilet seat.]
00:22:18 - Prediction: frontier, 1
00:22:18 - Next choice: Frontier at [54 98]
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:22:18 - Current position: [    -5.9732    0.050354      8.6939], 2.049
00:22:20 - 
== step: 2
00:22:21 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:22:23 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:22:23 - Step 2, update snapshots, 16 objects, 5 snapshots
00:22:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:25 - Prefiltering selected classes: ['mirror']
00:22:25 - Prefiltering snapshot: 5 -> 1
00:22:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:22:28 - Response: [snapshot 0]
Reason: [The snapshot does not show whether the toilet seat is open or closed.]
00:22:28 - Prediction: snapshot, 0
00:22:28 - The index of target snapshot 3
00:22:28 - Pred_target_class: mirror
00:22:28 - Next choice Snapshot of 2-view_1.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:22:28 - Current position: [    -5.3732    0.050354      8.1939], 2.830
00:22:30 - Question id f17869a2-2a4d-4ce4-b262-cb69618e3394 finished after arriving at target!
00:22:30 - Question id f17869a2-2a4d-4ce4-b262-cb69618e3394 finish successfully, 2.8300431805938095 length
00:22:30 - 38/41: Success rate: 38/38
00:22:30 - Mean path length for success exploration: 1.3329124382272841
00:22:30 - Filtered snapshots/Total snapshots/Total frames: 1/5/8
00:22:30 - Scene graph of question f17869a2-2a4d-4ce4-b262-cb69618e3394:
00:22:30 - Question: Is the toilet seat open or closed?
00:22:30 - Answer: Closed.
00:22:30 - Prediction: The snapshot does not show whether the toilet seat is open or closed.
00:22:30 - 0-view_1.png:
00:22:30 - 	1: telephone 1
00:22:30 - 	4: pillow 1
00:22:30 - 0-view_6.png:
00:22:30 - 	2: nightstand 3
00:22:30 - 	3: lamp 3
00:22:30 - 	27: picture 1
00:22:30 - 0-view_3.png:
00:22:30 - 	7: bed 4
00:22:30 - 	8: pillow 2
00:22:30 - 	12: pillow 1
00:22:30 - 	13: pillow 1
00:22:30 - 	14: blanket 1
00:22:30 - 0-view_5.png:
00:22:30 - 	11: cabinet 3
00:22:30 - 	16: picture 2
00:22:30 - 	18: curtain 2
00:22:30 - 	21: picture 1
00:22:30 - 	23: tv 1
00:22:30 - 2-view_1.png:
00:22:30 - 	28: mirror 2
00:22:30 - 
========
Index: 38 Scene: 00880-Nfvxx8J5NCo
00:22:33 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:22:33 - Load scene 00880-Nfvxx8J5NCo successfully with semantic texture
00:22:34 - 

Question id f2063c53-72d8-4cd8-b2cb-78ceee86449d initialization successful!
00:22:34 - 
== step: 0
00:22:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:22:36 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.09 seconds
00:22:38 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:22:39 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:22:41 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.11 seconds
00:22:43 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:22:45 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.12 seconds
00:22:46 - Step 0, update snapshots, 24 objects, 6 snapshots
00:23:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:23:03 - Prefiltering selected classes: ['counter']
00:23:03 - Prefiltering snapshot: 6 -> 1
00:23:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:23:07 - Response: [snapshot 0]
Reason: [There is nothing specifically detailed on the tray on the kitchen counter.]
00:23:07 - Prediction: snapshot, 0
00:23:07 - The index of target snapshot 4
00:23:07 - Pred_target_class: microwave stool trash bin counter
00:23:07 - Next choice Snapshot of 0-view_2.png
RuntimeWarning: invalid value encountered in divide
00:23:07 - Error in get_proper_snapshot_observation_point: cannot find a proper observation point among 16 candidates, return the snapshot center!
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:23:07 - Current position: [    -9.5166     0.18086    -0.34755], 0.000
00:23:09 - Question id f2063c53-72d8-4cd8-b2cb-78ceee86449d finished after arriving at target!
00:23:09 - Question id f2063c53-72d8-4cd8-b2cb-78ceee86449d finish successfully, 0.0 length
00:23:09 - 39/41: Success rate: 39/39
00:23:09 - Mean path length for success exploration: 1.2987351962214562
00:23:09 - Filtered snapshots/Total snapshots/Total frames: 1/6/7
00:23:09 - Scene graph of question f2063c53-72d8-4cd8-b2cb-78ceee86449d:
00:23:09 - Question: what is kept on the tray in the kitchen counter?
00:23:09 - Answer: banana
00:23:09 - Prediction: There is nothing specifically detailed on the tray on the kitchen counter.
00:23:09 - 0-view_0.png:
00:23:09 - 	1: couch 4
00:23:09 - 	2: coffee table 2
00:23:09 - 	3: book 2
00:23:09 - 	4: mat 1
00:23:09 - 0-view_6.png:
00:23:09 - 	8: fan 2
00:23:09 - 0-view_2.png:
00:23:09 - 	10: microwave 1
00:23:09 - 	11: stool 1
00:23:09 - 	12: trash bin 1
00:23:09 - 	13: counter 1
00:23:09 - 0-view_4.png:
00:23:09 - 	14: sink 4
00:23:09 - 	15: refrigerator 3
00:23:09 - 	25: paper bag 1
00:23:09 - 	27: tissue box 1
00:23:09 - 	29: picture 2
00:23:09 - 	32: cabinet 1
00:23:09 - 0-view_3.png:
00:23:09 - 	16: stool 3
00:23:09 - 	17: stool 2
00:23:09 - 	18: stool 2
00:23:09 - 	19: microwave 2
00:23:09 - 	20: picture 2
00:23:09 - 	21: shelf 2
00:23:09 - 	23: stove 2
00:23:09 - 0-view_5.png:
00:23:09 - 	37: shelf 1
00:23:09 - 	38: picture 1
00:23:09 - 
========
Index: 39 Scene: 00824-Dd4bFSTQ8gi
00:23:12 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:23:12 - Load scene 00824-Dd4bFSTQ8gi successfully with semantic texture
00:23:12 - 

Question id f5a17a09-ce4b-4123-bf40-d2239cf38cb8 initialization successful!
00:23:12 - 
== step: 0
00:23:13 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:23:15 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.10 seconds
00:23:16 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:23:18 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:23:19 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:23:20 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:23:22 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.07 seconds
00:23:22 - Step 0, update snapshots, 12 objects, 4 snapshots
00:23:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:23:25 - Prefiltering selected classes: ['sofa chair', 'folded chair', 'chair', 'table']
00:23:25 - Prefiltering snapshot: 4 -> 3
00:23:29 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:23:29 - Response: [snapshot 1]
Reason: [A potted plant is to the left of the front door.]
00:23:29 - Prediction: snapshot, 1
00:23:29 - The index of target snapshot 1
00:23:29 - Pred_target_class: potted plant picture folded chair
00:23:29 - Next choice Snapshot of 0-view_0.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:23:29 - Current position: [     6.3147    0.068824      0.7036], 1.000
00:23:31 - 
== step: 1
00:23:32 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.03 seconds
00:23:33 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:23:34 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:23:35 - Step 1, update snapshots, 13 objects, 5 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:23:36 - Current position: [     6.1147    0.068824      0.5036], 1.283
00:23:38 - Question id f5a17a09-ce4b-4123-bf40-d2239cf38cb8 finished after arriving at target!
00:23:38 - Question id f5a17a09-ce4b-4123-bf40-d2239cf38cb8 finish successfully, 1.2828427124746191 length
00:23:38 - 40/41: Success rate: 40/40
00:23:38 - Mean path length for success exploration: 1.2983378841277853
00:23:38 - Filtered snapshots/Total snapshots/Total frames: 3/5/8
00:23:38 - Scene graph of question f5a17a09-ce4b-4123-bf40-d2239cf38cb8:
00:23:38 - Question: What is to the left of the frontdoor?
00:23:38 - Answer: A storage closet
00:23:38 - Prediction: A potted plant is to the left of the front door.
00:23:38 - 0-view_0.png:
00:23:38 - 	1: potted plant 3
00:23:38 - 	2: picture 3
00:23:38 - 	4: folded chair 1
00:23:38 - 0-view_5.png:
00:23:38 - 	3: bed 4
00:23:38 - 	7: plate 3
00:23:38 - 	9: folded chair 2
00:23:38 - 	11: plate 2
00:23:38 - 	12: table 2
00:23:38 - 	21: chair 1
00:23:38 - 0-view_3.png:
00:23:38 - 	8: sofa chair 1
00:23:38 - 	10: pillow 1
00:23:38 - 0-view_4.png:
00:23:38 - 	14: picture 1
00:23:38 - 1-view_1.png:
00:23:38 - 	23: coffee table 1
00:23:38 - 
========
Index: 40 Scene: 00876-mv2HUxq3B53
00:23:44 - Loaded 192 classes from scannet 200: data/scannet200_classes.txt!!!
00:23:44 - Load scene 00876-mv2HUxq3B53 successfully with semantic texture
00:23:44 - 

Question id fc9d2a18-6197-4c8b-abd8-be0c493e5450 initialization successful!
00:23:44 - 
== step: 0
00:23:46 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.04 seconds
00:23:47 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:23:49 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.08 seconds
00:23:50 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:23:52 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:23:53 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:23:54 - Step 0, update snapshots, 15 objects, 4 snapshots
00:23:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:23:56 - Prefiltering selected classes: ['cabinet']
00:23:56 - Prefiltering snapshot: 4 -> 1
00:24:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:24:00 - Response: [snapshot 0]
Reason: [To check your outfit for a dinner party, you can use a full-length mirror or take a photo of yourself in your outfit to assess how it looks.]
00:24:00 - Prediction: snapshot, 0
00:24:00 - The index of target snapshot 0
00:24:00 - Pred_target_class: cabinet picture curtain picture tv
00:24:00 - Next choice Snapshot of 0-view_5.png
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:24:00 - Current position: [    -8.8732    0.050354      7.7939], 1.030
00:24:02 - 
== step: 1
00:24:03 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.05 seconds
00:24:04 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.02 seconds
00:24:05 - Done! Execution time of detections_to_obj_pcd_and_bbox function: 0.06 seconds
00:24:06 - Step 1, update snapshots, 15 objects, 4 snapshots
UserWarning: *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
00:24:07 - Current position: [    -9.2732    0.050354      7.4939], 1.530
00:24:09 - Question id fc9d2a18-6197-4c8b-abd8-be0c493e5450 finished after arriving at target!
00:24:09 - Question id fc9d2a18-6197-4c8b-abd8-be0c493e5450 finish successfully, 1.5295630140987002 length
00:24:09 - 41/41: Success rate: 41/41
00:24:09 - Mean path length for success exploration: 1.303977521444149
00:24:09 - Filtered snapshots/Total snapshots/Total frames: 1/4/9
00:24:09 - Scene graph of question fc9d2a18-6197-4c8b-abd8-be0c493e5450:
00:24:09 - Question: I want to check my outfit for a dinner party, how can I do this?
00:24:09 - Answer: Using the large mirror outside the first bedroom.
00:24:09 - Prediction: To check your outfit for a dinner party, you can use a full-length mirror or take a photo of yourself in your outfit to assess how it looks.
00:24:09 - 0-view_1.png:
00:24:09 - 	1: telephone 1
00:24:09 - 	4: pillow 1
00:24:09 - 0-view_6.png:
00:24:09 - 	2: nightstand 4
00:24:09 - 	3: lamp 3
00:24:09 - 	27: picture 1
00:24:09 - 0-view_3.png:
00:24:09 - 	7: bed 6
00:24:09 - 	8: pillow 3
00:24:09 - 	12: pillow 1
00:24:09 - 	13: pillow 1
00:24:09 - 	14: blanket 1
00:24:09 - 0-view_5.png:
00:24:09 - 	11: cabinet 5
00:24:09 - 	16: picture 3
00:24:09 - 	18: curtain 3
00:24:09 - 	21: picture 1
00:24:09 - 	23: tv 1
00:24:09 - Average number of filtered snapshots: 2.268292682926829
00:24:09 - Average number of total snapshots: 5.7073170731707314
00:24:09 - Average number of total frames: 8.560975609756097
00:24:09 - All scenes finish
Loading model...123
Model loaded.
len(success_list) 1
len(fail_list) 0
len(gpt_answer_list) 1
len(n_filtered_snapshots_list) 1
len(n_total_snapshots_list) 1
len(n_total_frames_list) 1
len(success_list) 2
len(fail_list) 0
len(gpt_answer_list) 2
len(n_filtered_snapshots_list) 2
len(n_total_snapshots_list) 2
len(n_total_frames_list) 2
len(success_list) 3
len(fail_list) 0
len(gpt_answer_list) 3
len(n_filtered_snapshots_list) 3
len(n_total_snapshots_list) 3
len(n_total_frames_list) 3
len(success_list) 4
len(fail_list) 0
len(gpt_answer_list) 4
len(n_filtered_snapshots_list) 4
len(n_total_snapshots_list) 4
len(n_total_frames_list) 4
len(success_list) 5
len(fail_list) 0
len(gpt_answer_list) 5
len(n_filtered_snapshots_list) 5
len(n_total_snapshots_list) 5
len(n_total_frames_list) 5
len(success_list) 6
len(fail_list) 0
len(gpt_answer_list) 6
len(n_filtered_snapshots_list) 6
len(n_total_snapshots_list) 6
len(n_total_frames_list) 6
len(success_list) 7
len(fail_list) 0
len(gpt_answer_list) 7
len(n_filtered_snapshots_list) 7
len(n_total_snapshots_list) 7
len(n_total_frames_list) 7
len(success_list) 8
len(fail_list) 0
len(gpt_answer_list) 8
len(n_filtered_snapshots_list) 8
len(n_total_snapshots_list) 8
len(n_total_frames_list) 8
len(success_list) 9
len(fail_list) 0
len(gpt_answer_list) 9
len(n_filtered_snapshots_list) 9
len(n_total_snapshots_list) 9
len(n_total_frames_list) 9
len(success_list) 10
len(fail_list) 0
len(gpt_answer_list) 10
len(n_filtered_snapshots_list) 10
len(n_total_snapshots_list) 10
len(n_total_frames_list) 10
len(success_list) 11
len(fail_list) 0
len(gpt_answer_list) 11
len(n_filtered_snapshots_list) 11
len(n_total_snapshots_list) 11
len(n_total_frames_list) 11
len(success_list) 12
len(fail_list) 0
len(gpt_answer_list) 12
len(n_filtered_snapshots_list) 12
len(n_total_snapshots_list) 12
len(n_total_frames_list) 12
len(success_list) 13
len(fail_list) 0
len(gpt_answer_list) 13
len(n_filtered_snapshots_list) 13
len(n_total_snapshots_list) 13
len(n_total_frames_list) 13
len(success_list) 14
len(fail_list) 0
len(gpt_answer_list) 14
len(n_filtered_snapshots_list) 14
len(n_total_snapshots_list) 14
len(n_total_frames_list) 14
len(success_list) 15
len(fail_list) 0
len(gpt_answer_list) 15
len(n_filtered_snapshots_list) 15
len(n_total_snapshots_list) 15
len(n_total_frames_list) 15
len(success_list) 16
len(fail_list) 0
len(gpt_answer_list) 16
len(n_filtered_snapshots_list) 16
len(n_total_snapshots_list) 16
len(n_total_frames_list) 16
len(success_list) 17
len(fail_list) 0
len(gpt_answer_list) 17
len(n_filtered_snapshots_list) 17
len(n_total_snapshots_list) 17
len(n_total_frames_list) 17
len(success_list) 18
len(fail_list) 0
len(gpt_answer_list) 18
len(n_filtered_snapshots_list) 18
len(n_total_snapshots_list) 18
len(n_total_frames_list) 18
len(success_list) 19
len(fail_list) 0
len(gpt_answer_list) 19
len(n_filtered_snapshots_list) 19
len(n_total_snapshots_list) 19
len(n_total_frames_list) 19
len(success_list) 20
len(fail_list) 0
len(gpt_answer_list) 20
len(n_filtered_snapshots_list) 20
len(n_total_snapshots_list) 20
len(n_total_frames_list) 20
len(success_list) 21
len(fail_list) 0
len(gpt_answer_list) 21
len(n_filtered_snapshots_list) 21
len(n_total_snapshots_list) 21
len(n_total_frames_list) 21
len(success_list) 22
len(fail_list) 0
len(gpt_answer_list) 22
len(n_filtered_snapshots_list) 22
len(n_total_snapshots_list) 22
len(n_total_frames_list) 22
len(success_list) 23
len(fail_list) 0
len(gpt_answer_list) 23
len(n_filtered_snapshots_list) 23
len(n_total_snapshots_list) 23
len(n_total_frames_list) 23
len(success_list) 24
len(fail_list) 0
len(gpt_answer_list) 24
len(n_filtered_snapshots_list) 24
len(n_total_snapshots_list) 24
len(n_total_frames_list) 24
len(success_list) 25
len(fail_list) 0
len(gpt_answer_list) 25
len(n_filtered_snapshots_list) 25
len(n_total_snapshots_list) 25
len(n_total_frames_list) 25
len(success_list) 26
len(fail_list) 0
len(gpt_answer_list) 26
len(n_filtered_snapshots_list) 26
len(n_total_snapshots_list) 26
len(n_total_frames_list) 26
len(success_list) 27
len(fail_list) 0
len(gpt_answer_list) 27
len(n_filtered_snapshots_list) 27
len(n_total_snapshots_list) 27
len(n_total_frames_list) 27
len(success_list) 28
len(fail_list) 0
len(gpt_answer_list) 28
len(n_filtered_snapshots_list) 28
len(n_total_snapshots_list) 28
len(n_total_frames_list) 28
Before filtering: 34
After filtering: 27
Before merging: 27
After merging: 26
Before filtering: 34
After filtering: 31
Before merging: 31
After merging: 30
len(success_list) 29
len(fail_list) 0
len(gpt_answer_list) 29
len(n_filtered_snapshots_list) 29
len(n_total_snapshots_list) 29
len(n_total_frames_list) 29
len(success_list) 30
len(fail_list) 0
len(gpt_answer_list) 30
len(n_filtered_snapshots_list) 30
len(n_total_snapshots_list) 30
len(n_total_frames_list) 30
len(success_list) 31
len(fail_list) 0
len(gpt_answer_list) 31
len(n_filtered_snapshots_list) 31
len(n_total_snapshots_list) 31
len(n_total_frames_list) 31
len(success_list) 32
len(fail_list) 0
len(gpt_answer_list) 32
len(n_filtered_snapshots_list) 32
len(n_total_snapshots_list) 32
len(n_total_frames_list) 32
len(success_list) 33
len(fail_list) 0
len(gpt_answer_list) 33
len(n_filtered_snapshots_list) 33
len(n_total_snapshots_list) 33
len(n_total_frames_list) 33
len(success_list) 34
len(fail_list) 0
len(gpt_answer_list) 34
len(n_filtered_snapshots_list) 34
len(n_total_snapshots_list) 34
len(n_total_frames_list) 34
len(success_list) 35
len(fail_list) 0
len(gpt_answer_list) 35
len(n_filtered_snapshots_list) 35
len(n_total_snapshots_list) 35
len(n_total_frames_list) 35
len(success_list) 36
len(fail_list) 0
len(gpt_answer_list) 36
len(n_filtered_snapshots_list) 36
len(n_total_snapshots_list) 36
len(n_total_frames_list) 36
len(success_list) 37
len(fail_list) 0
len(gpt_answer_list) 37
len(n_filtered_snapshots_list) 37
len(n_total_snapshots_list) 37
len(n_total_frames_list) 37
len(success_list) 38
len(fail_list) 0
len(gpt_answer_list) 38
len(n_filtered_snapshots_list) 38
len(n_total_snapshots_list) 38
len(n_total_frames_list) 38
len(success_list) 39
len(fail_list) 0
len(gpt_answer_list) 39
len(n_filtered_snapshots_list) 39
len(n_total_snapshots_list) 39
len(n_total_frames_list) 39
len(success_list) 40
len(fail_list) 0
len(gpt_answer_list) 40
len(n_filtered_snapshots_list) 40
len(n_total_snapshots_list) 40
len(n_total_frames_list) 40
len(success_list) 41
len(fail_list) 0
len(gpt_answer_list) 41
len(n_filtered_snapshots_list) 41
len(n_total_snapshots_list) 41
len(n_total_frames_list) 41
len(success_list) 41
len(fail_list) 0
len(gpt_answer_list) 41
len(n_filtered_snapshots_list) 41
len(n_total_snapshots_list) 41
len(n_total_frames_list) 41
